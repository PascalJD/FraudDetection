<!DOCTYPE HTML>
<!--
	Transitive by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body>

		<section id="one" class="wrapper style2">
			<div class="inner">
				<div>
					<div class="box">
						<div class="content">
							<header class="align-center">
								<h2>Détection de fraudes de cartes de crédit</h2>
								<p>IFT 3150 ‒ Projet d'informatique</p>
								<p>Pascal Jutras-Dubé <br> supervisé par Manuel Morales</p>
							</header>
							<hr/>

							<h3>Résumé</h3>
							<p>L'objectif du projet consiste en l'élaboration d'algorithmes de classification capables de détecter les transactions frauduleuses dans un dataset kaggle de transactions de cartes de crédit. Les données peuvent être trouvées <a href="https://www.kaggle.com/mlg-ulb/creditcardfraud" target="_blank">ici</a>.
							<br><br>
							Les cas de fraudes ne représentant que 0.173% du nombre total de transactions, l’implémentation des modèles et les métriques de mesures de performance utilisées doivent être adaptées aux données fortement débalancées. Il est également souhaitable que la classification soit sensible, c’est-à-dire que le taux des faux positifs soit minimal, puisque l'institution bancaire ne veut pas déranger inutilement ses clients.</p>

							<h3>Notebook</h3>
							<p>Une version récente, mais incomplète du notebook sur lequel je travaille est disponible <a href="https://github.com/PascalJD/FraudDetection/blob/master/D%C3%A9tection%20de%20fraude.ipynb" target="_blank">ici</a>. Pour éxécuter le code, assurez-vous d'avoir un dossier nommé data qui contient les données dans le même répertoire que le notebook.</p>

							<h3>Plan</h3>
							<p>Une ébauche de plan à laquelle je peux penser pour l'instant est la suivante. Il est fort probable que le plan évolue au fur et au mesure que le projet progresse.</p>
							<ul>
								<li>Undersampling</li>
								<ul>
									<li style="font-size: 15px;">aléatoire</li>
									<li style="font-size: 15px;">cluster centroid</li>
								</ul>
								
								<li>Oversampling</li>
								<ul>
									<li style="font-size: 15px;">SMOTE</li>
									<li style="font-size: 15px;">ADASYN</li>
									<li style="font-size: 15px;">GANs</li>
								</ul>

								<li>Oversampling et undersampling</li>
								
								<li>Réseaux de neurones</li>
								<ul>
									<li style="font-size: 15px;">Undersampling</li>
									<li style="font-size: 15px;">Oversampling</li>
								</ul>

								<li>Prétraitement avancé</li>
								<ul>
									<li style="font-size: 15px;">Autoencodeur</li>
									<li style="font-size: 15px;">Détection d'anomalies</li>
									<li style="font-size: 15px;">Traits caractéristiques discriminatifs</li>
								</ul>
							</ul>

							<h3>Rapports d'avancement</h3>
							<ul>
								<li>Semaine 1</li>
									<ul>
										<li style="font-size: 15px;">Lecture de la littérature</li>
										<p>J'ai lu certains articles et notebooks au sujet des données débalancées.</p>
										<li style="font-size: 15px;">Exploration des données</li>
										<p>Les données sont très débalancées: 492 fraudes parmi 284 807 transactions. 28 sur 30 traits caractéristiques résultent d'une réduction de dimensionalité par analyse en composantes principales (PCA). J'ai normalisé les deux traits restants, ceci aide à la convergence des divers algorithmes d'optimisation selon la littérature.</p>
										<li style="font-size: 15px;">Régression logistique</li>
										<p>J'ai testé un premier modèle sans trop me préoccuper du déséquilibre présent dans les données. Comme attendu, bien que ce modèle a une faible erreur de classification, il n'a su détecter que 64% des fraudes (validation croisée).</p>
										<li style="font-size: 15px;">Undersampling aléatoire</li>
										<p>J'ai implémenté une régression logistique, une machine à vecteurs de support (avec noyaux gaussien et polynomial), un k-plus-proches-voisins ainsi qu'un forêt d'arbres aléatoires. La recherche des meilleures combinaisons d'hyperparamètres s'est faite par validation croisée et la métrique utilisée est le recall (au lieu de l'accuracy). J'ai tracé les courbes ROC et la régression logistique semble avoir les meilleurs résultats.</p>
									</ul>

								<li>Semaine 2</li>
								<ul>
									<li style="font-size: 15px;">Undersampling aléatoire</li>
									<p>J'ai continuer l'évaluation de la méthode. J'ai ajouté des métriques d'évaluation.</p>
									<li style="font-size: 15px;">Méthodologie</li>
									<p>J'ai apporté des corrections méthodologiques importantes qui prévienne le surapprentissage lors de la validation croisée. Dans la phase de sélection du modèle des méthodes de resample, il est important de resample durant la validation croisée et de ne modifier que l'ensemble d'etraînement. Sinon on modifie forcément l'ensemble de validation et le prédicteur est optimisé pour des données resamplées. Le resample ne doit qu'agir sur l'entraînement pour que l'ensemble de validation corresponde à la vraie distribution.</p>
									<p>J'ai notamment implémenter une méthode pour abstraire la validation croisée avec re-sampling. Il y en a une pour optimiser les hyperparamètres et une pour estimer le performance. C'est méthodes fonctionnent pour des classifieurs et méthodes de re-sampling 'quelconques'.</p>
									<li style="font-size: 15px;">Undersampling par cluster et Smote</li>
									<p>J'ai commencé à étudier ces deux méthodes. Il faudra appliquer les modifications méthodologiques et les évaluer en détail.</p>
								</ul>

								<li>Semaine 3</li>
								<ul>
									<li style="font-size: 15px;">Oversampling</li>
									<p>J'ai implémenté des techniques qui ajoutent des exemples synthétiques de la classe minoritaire. SMOTE semble bien performer. Le désavantage des méthodes d'oversampling c'est qu'elles sont disposées au surapprentissage. En effet, on peut dupliquer les exemples aberrants ainsi que le bruit. C'est pourquoi il serait intéressant de refaire ces techniques, mais en ayant retiré les documents les plus atypiques.</p>
									<li style="font-size: 15px;">Réseaux de neurones (undersampling aléatoire)</li>
									<p>J'ai implémenté un premier réseau de neurones simple avec une seule couche cachée de 4 neurones et une sortie binaire sigmoïde. J'ai implémenté une méthode qui permet de faire un grid-search des hyperparamètres.</p>
								</ul>

								<li>Semaine 4</li>
								<ul>
									<li style="font-size: 15px;">Réseaux de neurones</li>
									<p>J'ai continué à étudier les réseaux de neurones. J'ai ajouté une architecture de modèle avec plus de neurones et de couches cachées. J'ai aussi modifié la méthode pour faire la recherche exhaustive d'hyperparamètres; entre autre pour qu'elle puisse évaluer l'aire sous la courbe roc pour évaluer la performance. Pour l'instant, les courbes d'entraînement sont particulières.</p>
								</ul>

								<li>Semaine 5</li>
								<ul>
									<li style="font-size: 15px;">Oversampling et Undersampling</li>
									<p>J'ai mélanger l'oversampling avec SMOTE et le undersampling aléatoire pour voir si on peut profiter le plus possible des avantages des deux méthodes.</p>
									<li style="font-size: 15px;">Autoencodeurs</li>
									<p>J'ai commencé le prétraitement avancé des données. Pour l'instant, je travaille sur les autoencodeurs. Ce sont des réseaux de neurones qui s'entraînent à reconstruire leurs entrées en minimisant l'erreur de reconstruction. Si on entraîne un auto-encodeur à apprendre la représentation des exemples non-frauduleux, alors on s'attend à ce que la représentation qu'il génère des exemples frauduleux soit différente de ceux non-frauduleux. Les autoencodeurs devraient aider la classification en accentuant les différences entre les cas de fraudes et les cas normaux.</p>
								</ul>
								<li>Semaine 6</li>
								<ul>
									<li style="font-size: 15px;">Autoencodeurs</li>
									<p>J’ai entraîné un autoencodeur à reconstruire des transactions non-frauduleuses pour que la représentation qu'il génère des exemples frauduleux soit différente, et ce, en espérant qu'il puisse renforcer les différences entre les cas normaux et les cas de fraudes. Toutefois, les graphiques des données projetées par t-SNE suggèrent que les regroupements de données aient plus de variabilité après qu'elles aient été transformées par l'autoencodeur, nuisant à la séparabilité des classes. En effet, les classifieurs ont des pertes de performance lorsqu'ils s'entraînent sur les données transformées par l'autoencodeur avec undersampling aléatoire.
									<p>On pourrait faire un usage tout autre des autoencodeurs. Dans la perspective d'un apprentissage semi-suppervié, on peut utiliser l'auto-encodeur comme classifieur en utilisant l'erreur de reconstruction comme discriminant entre les des catégories de transactions.
									</p>
								</ul>
								<li>Semaine 7</li>
								<ul>
									<li style="font-size: 15px;">GANs</li>
									<p>Un GAN (Generative adversarial network) est un réseau de neurones génératif dans lequel deux réseaux sont en compétition. Le premier réseau est le générateur dont la tache est de générer des exemples qui borneront le second réseau, soit le discriminateur, qui lui est entraîné à distinguer les vrais exemples des faux exemples.</p>
									<p>Dans notre cas, ils peuvent être utilisés afin de générer des transactions frauduleuses synthétiques pour augmenter, voire balancer le jeu de données. Cette méthode d'oversampling pourra peut-être donner lieu à des meilleurs résultats (recall, ROC, accuracy, etc.) que SMOTE et ADASYN pour certains classifieurs.
									</p>
									<p>Cette semaine, j'ai donc consulté la littérature en ligne au sujet des GANs pour m'informer sur leur fonctionnement. J'ai également implémenter un premier réseau adversériel génératif de base en suivant un tutoriel en ligne. Le réseau est capable de générer des exemples, mais pour l'instant ces exemples ne ressemblent pas suffisamment aux transactions frauduleuses pour aider à la classification.
									</p>
								</ul>
								<li>Semaine 8</li>
								<ul>
									<p>J'ai continué à lire un peu sur les GANs, mais sans toucher à l'implémentation comme c'était la semaine des intras. Je compte poursuivre l'implémentation cette semaine. </p>
								</ul>
								<li>Semaine 9</li>
									<li style="font-size: 15px;">Autoencodeurs variationnels</li>
									<p>
										Monsieur Morales m'a recommandé d'essayer les autoencodeurs variationnels avant les GANs. Les autoencodeurs variationnels sont aussi des modèles génératifs qui pourraient être utilisés pour sur-échantillonner la classe majoritaire.
									</p>
									<p>
										Cette semaine, j'ai lu la théorie sur les autoencodeurs variationnels et sur comment ils peuvent être utilisés pour générer des données. J'ai également implémenté un premier modèle qui semble apprendre convenablement la distribution des données.
									</p>
								<li>Semaine 10</li>
									<li style="font-size: 15px;">Autoencodeurs variationnels</li>
									<p>
										J'ai continué l'implémentation des auto-encodeurs variationnels. Les résultats semblent bons mais le modèle peut être optimisé.
									</p>
									<p>
										D'autre part, j'ai continué de lire la littérature au sujet des autoencodeurs variationnels pour mieux comprendre les exemples et les implémentations que j'ai trouvés en ligne. Je me suis particulièrement penché sur les fondements théoriques et j'en parlerai dans la rédaction du rapport.
									</p>
								<li>Semaine 11</li>
									<li style="font-size: 15px;">Autoencodeurs variationnels</li>
									<p>
										Les résultats sont prometteurs pour les autoencodeurs variationnels. Il y a une baisse de rappel (recall) comparativement aux méthodes explorées précédemment, mais la précision et le score f1 sont beaucoup plus élevés. Le taux de bonnes classifications est aussi nettement suppérieur que pour les méthodes de ré-échantillonnage précédemment étudiées.
									</p>
									<p>
										J'ai ajouté des figures au notebook. J'ai notamment imprimé des graphiques pour visuliser la représentation latente apprise par le réseau d'inférence et j'ai aussi imprimé des graphiques avec réduction de dimensionalité T-sne pour visualiser les données synthétiquement créées par le réseau génératif.
									</p>
								<li>Semaine 12</li>
									<p>Cette semaine j'ai avancé un peu la rédaction et travaillé sur quelques figures</p>
									<li style="font-size: 15px;">Autoencodeurs variationnels</li>
									<p>
										J'ai commencé à travailler autrement avec les auto-encodeurs et je poursuivrai ceci dans les prochaines semaines. Les auto-encodeurs peuvent être utilisés pour établir directement une classification dans le cadre d'un apprentissage non-supervisé (sans classe).
									</p>
									<p>
										Si un auto-encodeur s'entraîne seulement sur les transactions normales, alors il va apprendre à les reproduire. De là on s'attend qu'il éprouve des difficultés à reproduire fidèlement les cas de fraudes puisque ses poids ont été appris en fonction des transactions normales. Pour cette raison, le coût de reconstruction devrait être élevé pour les fraudes de sorte qu'on peut décider qu'on classifie les exemples qui ont une erreur de reconstruction suppérieure à une certaint borne comme des fraudes.
									</p>
								<li>Semaine 13</li>
									<li style="font-size: 15px;">Autoencodeurs variationnels</li>
									<p>
										J'ai obtenu des premiers résultats avec un autoencodeur variationnel pour la détection d'anomalie en apprentissage non-supervisé. Pour ce faire, j'ai implémenté une fonctionnalité qui calcule la probabilité de reconstruction de la sortie du réseaux en fonction de l'entrée et identifié un seuil critique sur cette probabilité qui permet de discriminer entre une transaction saine et une fraude.
									</p>
									<p>
										Pour l'instant les résultats sont décents, mais moins bon que pour les autres méthodes. Par contre, comme on a accès aux classes, on peut toujours optimiser le modèle. C'est ce sur quoi je vais travailler dans la prochaine semaine. En particulier je vais tester différentes architectures de réseaux et différentes tailles pour la représentation latente.
									</p>
								</ul>
								
							</ul>

						</div>
					</div>
				</div>
			</div>
		</section>

	</body>
</html>
