<!DOCTYPE HTML>
<!--
	Transitive by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body>

		<section id="one" class="wrapper style2">
			<div class="inner">
				<div>
					<div class="box">
						<div class="content">
							<header class="align-center">
								<h2>Détection de fraudes de cartes de crédit</h2>
								<p>IFT 3150 ‒ Projet d'informatique</p>
								<p>Pascal Jutras-Dubé <br> supervisé par Manuel Morales</p>
							</header>
							<hr/>

							<h3>Résumé</h3>
							<p>L'objectif du projet consiste en l'élaboration d'algorithmes de classification capables de détecter les transactions frauduleuses dans un dataset kaggle de transactions de cartes de crédit. Les données peuvent être trouvées <a href="https://www.kaggle.com/mlg-ulb/creditcardfraud" target="_blank">ici</a>.
							<br><br>
							Les cas de fraudes ne représentant que 0.173% du nombre total de transactions, l’implémentation des modèles et les métriques de mesures de performance utilisées doivent être adaptées aux données fortement débalancées. Il est également souhaitable que la classification soit sensible, c’est-à-dire que le taux des faux positifs soit minimal, puisque l'institution bancaire ne veut pas déranger inutilement ses clients.</p>

							<h3>Notebook</h3>
							<p>Une version récente, mais incomplète du notebook sur lequel je travaille est disponible <a href="https://github.com/PascalJD/FraudDetection/blob/master/D%C3%A9tection%20de%20fraude.ipynb" target="_blank">ici</a>. Pour éxécuter le code, assurez-vous d'avoir un dossier nommé data qui contient les données dans le même répertoire que le notebook.</p>

							<h3>Plan</h3>
							<p>Une ébauche de plan à laquelle je peux penser pour l'instant est la suivante. Il est fort probable que le plan évolue au fur et au mesure que le projet progresse.</p>
							<ul>
								<li>Undersampling</li>
								<ul>
									<li style="font-size: 15px;">aléatoire</li>
									<li style="font-size: 15px;">cluster centroid</li>
								</ul>
								
								<li>Oversampling</li>
								<ul>
									<li style="font-size: 15px;">SMOTE</li>
									<li style="font-size: 15px;">ADASYN</li>
									<li style="font-size: 15px;">GANs</li>
								</ul>

								<li>Oversampling et undersampling</li>
								
								<li>Réseaux de neurones</li>
								<ul>
									<li style="font-size: 15px;">Undersampling</li>
									<li style="font-size: 15px;">Oversampling</li>
								</ul>

								<li>Prétraitement avancé</li>
								<ul>
									<li style="font-size: 15px;">Autoencodeur</li>
									<li style="font-size: 15px;">Détection d'anomalies</li>
									<li style="font-size: 15px;">Traits caractéristiques discriminatifs</li>
								</ul>
							</ul>

							<h3>Rapports d'avancement</h3>
							<ul>
								<li>Semaine 1</li>
									<ul>
										<li style="font-size: 15px;">Lecture de la littérature</li>
										<p>J'ai lu certains articles et notebooks au sujet des données débalancées.</p>
										<li style="font-size: 15px;">Exploration des données</li>
										<p>Les données sont très débalancées: 492 fraudes parmi 284 807 transactions. 28 sur 30 traits caractéristiques résultent d'une réduction de dimensionalité par analyse en composantes principales (PCA). J'ai normalisé les deux traits restants, ceci aide à la convergence des divers algorithmes d'optimisation selon la littérature.</p>
										<li style="font-size: 15px;">Régression logistique</li>
										<p>J'ai testé un premier modèle sans trop me préoccuper du déséquilibre présent dans les données. Comme attendu, bien que ce modèle a une faible erreur de classification, il n'a su détecter que 64% des fraudes (validation croisée).</p>
										<li style="font-size: 15px;">Undersampling aléatoire</li>
										<p>J'ai implémenté une régression logistique, une machine à vecteurs de support (avec noyaux gaussien et polynomial), un k-plus-proches-voisins ainsi qu'un forêt d'arbres aléatoires. La recherche des meilleures combinaisons d'hyperparamètres s'est faite par validation croisée et la métrique utilisée est le recall (au lieu de l'accuracy). J'ai tracé les courbes ROC et la régression logistique semble avoir les meilleurs résultats.</p>
									</ul>

								<li>Semaine 2</li>
								<ul>
									<li style="font-size: 15px;">Undersampling aléatoire</li>
									<p>J'ai continuer l'évaluation de la méthode. J'ai ajouté des métriques d'évaluation.</p>
									<li style="font-size: 15px;">Méthodologie</li>
									<p>J'ai apporté des corrections méthodologiques importantes qui prévienne le surapprentissage lors de la validation croisée. Dans la phase de sélection du modèle des méthodes de resample, il est important de resample durant la validation croisée et de ne modifier que l'ensemble d'etraînement. Sinon on modifie forcément l'ensemble de validation et le prédicteur est optimisé pour des données resamplées. Le resample ne doit qu'agir sur l'entraînement pour que l'ensemble de validation corresponde à la vraie distribution.</p>
									<p>J'ai notamment implémenter une méthode pour abstraire la validation croisée avec re-sampling. Il y en a une pour optimiser les hyperparamètres et une pour estimer le performance. C'est méthodes fonctionnent pour des classifieurs et méthodes de re-sampling 'quelconques'.</p>
									<li style="font-size: 15px;">Undersampling par cluster et Smote</li>
									<p>J'ai commencé à étudier ces deux méthodes. Il faudra appliquer les modifications méthodologiques et les évaluer en détail.</p>
								</ul>

								<li>Semaine 3</li>
								<ul>
									<li style="font-size: 15px;">Oversampling</li>
									<p>J'ai implémenté des techniques qui ajoutent des exemples synthétiques de la classe minoritaire. SMOTE semble bien performer. Le désavantage des méthodes d'oversampling c'est qu'elles sont disposées au surapprentissage. En effet, on peut dupliquer les exemples aberrants ainsi que le bruit. C'est pourquoi il serait intéressant de refaire ces techniques, mais en ayant retiré les documents les plus atypiques.</p>
									<li style="font-size: 15px;">Réseaux de neurones (undersampling aléatoire)</li>
									<p>J'ai implémenté un premier réseau de neurones simple avec une seule couche cachée de 4 neurones et une sortie binaire sigmoïde. J'ai implémenté une méthode qui permet de faire un grid-search des hyperparamètres.</p>
								</ul>

								<li>Semaine 4</li>
								<ul>
									<li style="font-size: 15px;">Réseaux de neurones</li>
									<p>J'ai continué à étudier les réseaux de neurones. J'ai ajouté une architecture de modèle avec plus de neurones et de couches cachées. J'ai aussi modifié la méthode pour faire la recherche exhaustive d'hyperparamètres; entre autre pour qu'elle puisse évaluer l'aire sous la courbe roc pour évaluer la performance. Pour l'instant, les courbes d'entraînement sont particulières.</p>
								</ul>

								<li>Semaine 5</li>
								<ul>
									<li style="font-size: 15px;">Oversampling et Undersampling</li>
									<p>J'ai mélanger l'oversampling avec SMOTE et le undersampling aléatoire pour voir si on peut profiter le plus possible des avantages des deux méthodes.</p>
									<li style="font-size: 15px;">Autoencodeurs</li>
									<p>J'ai commencé le prétraitement avancé des données. Pour l'instant, je travaille sur les autoencodeurs. Ce sont des réseaux de neurones qui s'entraînent à reconstruire leurs entrées en minimisant l'erreur de reconstruction. Si on entraîne un auto-encodeur à apprendre la représentation des exemples non-frauduleux, alors on s'attend à ce que la représentation qu'il génère des exemples frauduleux soit différente de ceux non-frauduleux. Les autoencodeurs devraient aider la classification en accentuant les différences entre les cas de fraudes et les cas normaux.</p>
								</ul>
								<li>Semaine 6</li>
								<ul>
									<li style="font-size: 15px;">Autoencodeurs</li>
									<p>J’ai entraîné un autoencodeur à reconstruire des transactions non-frauduleuses pour que la représentation qu'il génère des exemples frauduleux soit différente, et ce, en espérant qu'il puisse renforcer les différences entre les cas normaux et les cas de fraudes. Toutefois, les graphiques des données projetées par t-SNE suggèrent que les regroupements de données aient plus de variabilité après qu'elles aient été transformées par l'autoencodeur, nuisant à la séparabilité des classes. En effet, les classifieurs ont des pertes de performance lorsqu'ils s'entraînent sur les données transformées par l'autoencodeur avec undersampling aléatoire.
									<p>On pourrait faire un usage tout autre des autoencodeurs. Dans la perspective d'un apprentissage semi-suppervié, on peut utiliser l'auto-encodeur comme classifieur en utilisant l'erreur de reconstruction comme discriminant entre les des catégories de transactions.
									</p>
								</ul>

							</ul>

						</div>
					</div>
				</div>
			</div>
		</section>

	</body>
</html>
