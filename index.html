<!DOCTYPE HTML>
<!--
	Transitive by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body>

		<section id="one" class="wrapper style2">
			<div class="inner">
				<div>
					<div class="box">
						<div class="content">
							<header class="align-center">
								<h2>Détection de fraudes de cartes de crédit</h2>
								<p>IFT 3150 ‒ Projet d'informatique</p>
								<p>Pascal Jutras-Dubé <br> supervisé par Manuel Morales</p>
							</header>
							<hr/>

							<h3>Résumé</h3>
							<p>L'objectif du projet consiste en l'élaboration d'algorithmes de classification capables de détecter les transactions frauduleuses dans un dataset kaggle de transactions de cartes de crédit. Les données peuvent être trouvées <a href="https://www.kaggle.com/mlg-ulb/creditcardfraud">ici</a>.
							<br><br>
							Les cas de fraudes ne représentant que 0.173% du nombre total de transactions, l’implémentation des modèles et les métriques de mesures de performance utilisées doivent être adaptées aux données fortement débalancées. Il est également souhaitable que la classification soit sensible, c’est-à-dire que le taux des faux positifs soit minimal, puisque l'institution bancaire ne veut pas déranger inutilement ses clients.</p>

							<h3>Notebook</h3>
							<p>Le notebook est disponible <a href="https://github.com/PascalJD/FraudDetection/blob/master/D%C3%A9tection%20de%20fraude.ipynb">ici</a>. Pour éxécuter le code, assurez-vous d'avoir un dossier nommé data qui contient les données à l'emplacement du notebook.</p>

							<h3>Plan</h3>
							<p>Une ébauche de plan à laquelle je peux penser pour l'instant est la suivante. Il est fort probable que le plan évolue au fur et au mesure que le projet progresse.</p>
							<ul>
								<li>Undersampling</li>
								<ul>
									<li style="font-size: 15px;">aléatoire</li>
									<li style="font-size: 15px;">cluster</li>
									<li style="font-size: 15px;">méthode d'ensemble</li>
								</ul>
								
								<li>Oversampling</li>
								<ul>
									<li style="font-size: 15px;">aléatoire</li>
								</ul>
								
								<li>SMOTE</li>
								<li>Réseau de neurones</li>
								<li>Prétraitement avancé</li>
							</ul>

							<h3>Rapports d'avancement</h3>
							<ul>
								<li>Semaine 1</li>
									<ul>
										<li style="font-size: 15px;">Lecture de la littérature</li>
										<p>J'ai lu certains articles et notebooks au sujet des données débalancées.</p>
										<li style="font-size: 15px;">Exploration des données</li>
										<p>Les données sont très débalancées: 492 fraudes parmi 284 807 transactions. 28 sur 30 traits caractéristiques résultent d'une réduction de dimensionalité par analyse en composantes principales (PCA). J'ai normalisé les deux traits restants, ceci aide à la convergence des divers algorithmes d'optimisation selon la littérature.</p>
										<li style="font-size: 15px;">Régression logistique</li>
										<p>J'ai testé un premier modèle sans trop me préoccuper du déséquilibre présent dans les données. Comme attendu, bien que ce modèle a une faible erreur de classification, il n'a su détecter que 64% des fraudes (validation croisée).</p>
										<li style="font-size: 15px;">Undersampling aléatoire</li>
										<p>J'ai implémenté une régression logistique, une machine à vecteurs de support (avec noyaux gaussien et polynomial), un k-plus-proches-voisins ainsi qu'un forêt d'arbres aléatoires. La recherche des meilleures combinaisons d'hyperparamètres s'est faite par validation croisée et la métrique utilisée est le recall (au lieu de l'accuracy). J'ai tracé les courbes ROC et la régression logistique semble avoir les meilleurs résultats.</p>
									</ul>

								<li>Semaine 2</li>
								<ul>
									<li style="font-size: 15px;">Undersampling aléatoire</li>
									<p>J'ai continuer l'évaluation de la méthode. J'ai ajouté des métriques d'évaluation.</p>
									<li style="font-size: 15px;">Méthodologie</li>
									<p>J'ai apporté des corrections méthodologiques importantes qui prévienne le surapprentissage lors de la validation croisée. Dans la phase de sélection du modèle des méthodes de resample, il est important de resample durant la validation croisée et de ne modifier que l'ensemble d'etraînement. Sinon on modifie forcément l'ensemble de validation et le prédicteur est optimisé pour des données resamplées. Le resample ne doit qu'agir sur l'entraînement pour que l'ensemble de validation corresponde à la vraie distribution.</p>
									<p>J'ai notamment implémenter une méthode pour abstraire la validation croisée avec re-sampling. Il y en a une pour optimiser les hyperparamètres et une pour estimer le performance. C'est méthodes fonctionnent pour des classifieurs et méthodes de re-sampling 'quelconques'.</p>
									<li style="font-size: 15px;">Undersampling par cluster et Smote</li>
									<p>J'ai commencé à étudier ces deux méthodes. Il faudra appliquer les modifications méthodologiques et les évaluer en détail.</p>

								</ul>
							</ul>
						</div>
					</div>
				</div>
			</div>
		</section>

	</body>
</html>
