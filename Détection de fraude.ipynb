{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection de fraudes de cartes de crédit\n",
    "\n",
    "## 1 Introduction\n",
    "\n",
    "La détection de fraudes par cartes de crédit est un sujet de recherche majeur en finance ayant des répercussions économiques importantes. Il est important que les sociétés de carte de crédit puissent reconnaître les transactions frauduleuses pour que leurs clients ne soient pas facturés pour des articles qu'ils n'ont pas achetés. L'objectif du projet est d'explorer différents algorithmes de classification en apprentissage automatique capables de détecter les fraudes dans un ensemble de transactions bancaires. Le [jeu de données](https://www.kaggle.com/mlg-ulb/creditcardfraud) étudié dans le cadre du projet est un jeu de données kaggle de transactions par cartes de crédit.\n",
    "\n",
    "En pratique, les fraudes sont ponctuelles et sous représentées dans le jeu de données qui contient principalement des transactions normales. L'implémentation des modèles et les métriques de mesures de performance utilisées doivent être adaptées aux données fortement débalancées. C'est la raison pour laquelle on étudiera différentes méthodes qui permettent de traiter des jeux de donnés caractérisés par un déséquilibre marqué entre les classes dans un contexe de classification.\n",
    "\n",
    "D'autre part, il est également souhaitable que la classification soit sensible, c’est-à-dire que le taux de transactions classées à tort comme des fraudes soit minimal puisque l'institution bancaire ne veut pas déranger inutilement ces clients.\n",
    "\n",
    "\n",
    "## 2 Plan\n",
    "\n",
    "* [3 Données](#Donnees)\n",
    "* [4 Méthodologie](#Methodologie)\n",
    "  * 4.1 Fonctions utilitaires\n",
    "* [5 Normalisation](#Normalization)\n",
    "* [6 Séparation des données](#Split)\n",
    "* [7 Régression logistique (implémentation naïve)](#Reg)\n",
    "  * 7.1 Sélection des hyperparamètres\n",
    "  * 7.2 Évaluation sur les données test\n",
    "* [8 Sous-échantillonnage](#Us)\n",
    "  * 8.1 Sous-échantillonnage aléatoire\n",
    "    * 8.1.1 Sélection du modèle \n",
    "  * 8.2 Sous échantillonnage par centroïdes\n",
    "    * 8.2.1 Sélection des hyperparamètres\n",
    "  * 8.3 Évaluation sur les données test (sous-échantillonnage aléatoire)\n",
    "* [9 Sur-échantillonnage synthétique](#Smote)\n",
    "  * 9.1 SMOTE\n",
    "    * 9.1.1 Sélection des hyperparamètres\n",
    "  * 9.2 ADASYN\n",
    "    * 9.2.1 Sélection des hyperparamètres\n",
    "  * 9.3 Évaluation sur les données test (SMOTE)\n",
    "* [10 Sur-échantillonnage avec autoencodeur variationnel](#Vae)\n",
    "  * 10.1 Théorie\n",
    "  * 10.2 Implémentation\n",
    "  * 10.3 Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time as t\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Resampling\n",
    "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support,\\\n",
    "                            accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfpd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Donnees\"></a>\n",
    "## 3 Données\n",
    "\n",
    "Le jeu de données contient 284 807 exemples ayant chacun 30 traits caractéristiques numériques dont le temps et le montant de la transaction. Les 28 autres proviennent d'une analyse en composante principale (PCA) effectuée pour anonymiser les données. Très sommairement, une analyse en composante principale est une réduction de dimensionalité qui consiste à projeter les variables initiales sur des nouvelles variables décorrélés qu'on appelle les composantes principales.\n",
    "\n",
    "Les exemples non-frauduleux sont étiquetés par la classe 0 et les exemples frauduleux par la classe 1. Seulement 492 (0.173%) des exemples sont de la classe 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (284807, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/creditcard.csv\")\n",
    "print('shape: ', df.shape)\n",
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Class</th>\n",
       "      <th>Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Non-fraud</td>\n",
       "      <td>284315</td>\n",
       "      <td>99.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fraud</td>\n",
       "      <td>492</td>\n",
       "      <td>0.173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label   Class   Ratio\n",
       "0  Non-fraud  284315  99.827\n",
       "1      fraud     492   0.173"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = df['Class'].value_counts().to_frame()\n",
    "count['Ratio'] = count['Class'].apply(lambda x: np.around(x/len(df)*100, 3))\n",
    "count.insert(0, 'Label', ['Non-fraud', 'fraud'])\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les colonnes `Time` et `Amount` sont les plus asymétriques, les autres sont normalisées. Ci-bas les histogrammes de chaque trait caractéristique des données en fonction des classes. Ils illustrent que certains traits caractéristiques semblent plus discriminatifs que d'autres qui sont plus confondus pour les deux classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x1152 with 31 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_features = df.shape[1] #- 1 \n",
    "n_cols = 4\n",
    "n_rows = n_features // n_cols + 1\n",
    "\n",
    "# create a figure and a set of subplots\n",
    "axarr = [[]]*n_features\n",
    "fig, ax = plt.subplots(figsize=(n_cols*3.5, n_rows*2))\n",
    "\n",
    "for i, col in enumerate(df):\n",
    "    # Create an axis at specific location inside a regular grid.\n",
    "    axarr[i] = plt.subplot2grid( shape=(n_rows, n_cols), loc=(i // n_cols, i % 4))\n",
    "    # Generate histograms\n",
    "    # bins are 25 evenly spaced numbers between 0.2 and 99.8 perceniles (not including extreme values)\n",
    "    bins = np.linspace(start=np.percentile(df[col], 0.2), stop=np.percentile(df[col], 99.8), num=25)\n",
    "    axarr[i].hist(x=[df.loc[df.Class == 0, col], df.loc[df.Class == 1, col]],\n",
    "                  label=['normal', 'fraud'],\n",
    "                  bins=bins,\n",
    "                  color=['blue', 'red'],\n",
    "                  normed=True)\n",
    "    axarr[i].set_xlabel(col, size=12)\n",
    "    if i == 0: \n",
    "        legend = axarr[i].legend()\n",
    "\n",
    "plt.tight_layout(rect=[0,0,1,0.95]) # xmin, ymin, xmax, ymax\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Methodologie\"></a>\n",
    "\n",
    "## 4 Méthodologie\n",
    "\n",
    "Un classifieur entraîné sur des données grandement débalancées risque de mémoriser la disproportion des classes et d'apprendre alors à voter majoriatirement pour la classe sur-représentée. Un tel classifieur sur-apprend la distribution et ignore les traits caractéristiques permettant véritablement de discriminer entre les classes. Considérons l'exemple d'un classifieur qui prédit toujours la classe 0 pour le présent problème de détection de fraudes. Il réussit à prédire correctement la classe de 99.827% transactions, sans pourtant ne détecter aucune fraude. Ce classifieur est incapable de généraliser, et ce, même si son taux de classifications est élevé. C'est la raison pour laquelle il faut adapter l'entraînement des classifieurs et évaluer leurs performances avec les métriques appropriées.\n",
    "\n",
    "Pour minimiser le risque de sur-apprentissage lié au déséquilibre des données, il est possible de ré-échantillonner l'ensemble des données afin de l'équilibrer. L'idée est d'entraîner un modèle sur un ensemble de données balancé tel quel 50% des données sont des fraudes. Modifier ainsi les données d'entraînement introduit un biais qui sert à compenser le risque de surapprentissage dû au fléau des données débalancées. \n",
    "\n",
    "Le sous-échantillonnage est une méthode de ré-échantillonnage qui consiste à retirer une partie des données de la classe majoritaire avant d'entraîner un classifieur. Inversement, le sur-échantillonnage consiste à augmenter les données de la classe minoritaire. On présentera plusieurs méthodes de ré-échantillonnge pour parvenir à reconnaître les fraudes. \n",
    "\n",
    "D'autre part, voici une liste énumérant les définitions de différentes métriques pour mesurer la performance des algorithmes de classification basées sur les notions de vrai positif, faux positif, vrai négatif et faux négatif.\n",
    "\n",
    "- vrais positifs (VP): Nombre de fraudes classées correctement.\n",
    "\n",
    "\n",
    "- faux positifs (FP): Nombre de non-fraudes classées incorrectement.\n",
    "\n",
    "\n",
    "- vrais négatifs (VN): Nombre de non-fraudes classées correctement.\n",
    "\n",
    "\n",
    "- faux négatifs (FN): Nombre de fraudes classées incorrectement.\n",
    "\n",
    "Note: On peut aussi énoncer les définitions pour VP, FP, VN et FN symétriquement pour la classe non-fraude.\n",
    "\n",
    "Soit $N$ le nombre total d'exemples.\n",
    "\n",
    "- Taux de bonnes classifications (accuracy) $:=\\frac{VP+VN}{N}$\n",
    "\n",
    "\n",
    "- Précision (precision) $:=\\frac{VP}{VP+FP}$\n",
    "\n",
    "\n",
    "- Rappel (recall) $:=\\frac{VP}{VP+FN}$\n",
    "\n",
    "\n",
    "- Score-f1 (f1-score)$:=2\\ \\frac{\\text{précision}\\ \\times\\ \\text{rappel}}{\\text{précision}\\ +\\ \\text{rappel}}$\n",
    "\n",
    "\n",
    "- Courbe ROC: Courbe de VP en fonction de FP pour un classifieur binaire.\n",
    "\n",
    "\n",
    "- Roc Auc Score: Aire sous la courbe ROC.\n",
    "\n",
    "\n",
    "Le taux de bonnes classifications est peut-être la mesure la plus naturelle lorsque le jeu de données est balancé. Par contre, on a vu qu'il peut être trompeur si les classes sont disproportionnées.\n",
    "\n",
    "La précision et le rappel sont des mesures de performance appropriées dans le cas de données débalancées. La précision est une mesure d'exactitude qui correspond à la proportion des items pertinents parmi l'ensemble des items proposés. Dans notre cas, il s'agit de l'ensemble des fraudes détectées parmi l'ensemble des transactions classées comme fraudes. D'autre part, le rappel (ou sensibilité) est une mesure d'exhaustivité. Le rappel est la proportion des items pertinents proposés parmi l'ensemble des items pertinents. C'est-à-dire qu'il s'agit de l'ensemble des fraudes détectées parmi l'ensemble de toutes les fraudes. C'est le taux de bonnes classifications par classe. \n",
    "\n",
    "Dans les cas extrêmes, la précision et le rappel s'échangent l'un pour l'autre sous la forme d'un compromis. Par exemple, si on prédit une seule fraude comme une fraude et toutes les autres transactions comme des non-fraudes, alors la précision est de 100%, mais le rappel est très proche de 0%. Inversement, si on prédit toutes les transactions comme des fraudes, alors le rappel est de 100%, mais la précision est très basse. Le score-f1 est la moyenne harmonique de la précision et du rappel qui quantifie le compromis entre la précision et le rappel. \n",
    "\n",
    "Si la probabilité associée à chaque classe est disponible, alors il est possible de tracer la courbe de la précision en fonction du rappel pour différents seuils de classification. Il est également possible de tracer la courbe ROC qui est le taux de vrais positifs en fonction du taux de faux négatifs calculés pour différents seuils de classification. \n",
    "\n",
    "### Fonctions utilitaires\n",
    "\n",
    "Il faut être vigilant lorsqu'on applique les méthodes de ré-échantillonnage puisqu'elles modifient la distribution des données. Supposons qu'on utilise une technique de sur-échantillonnage qui duplique aléatoirement des exemples de la classe minoritaire. Si on sur-échantillonne avant de séparer les données en ensembles d'entraînement et de test, alors il probable qu'un exemple soit dans l'ensemble d'entraînement mais que sa copie soit dans l'ensemble de test. Ainsi, l'ensemble de test n'est pas complètement inconnu à un classifieur qui s'entraîne sur cet ensemble d'entraînement. Pour éviter une telle fuite d'information future et l'introduction d'un biais dans l'estimation de performance, il faut s'assurer que l'ensemble de test soit indépendant de l'ensemble d'entraînement et que sa distribution soit celle des données initiales. C'est aussi valable lors de la validation croisée: il faut que les méthodes de ré-échantillonnage s'appliquent autant que possible sur l'ensemble d'entraînement sans affecter l'ensemble de validation.\n",
    "\n",
    "La fonctionalité `grid_search_cv_resample` permet de faire une fouille exhaustive sur un dictionnaire d'hyper-paramètres tout en ré-échantillonnant durant la validation croisée. La méthode  `GridSearchCV` de Scikit Learn est plus rapide d'éxécution mais ne permet pas de ré-échantillonner à chaque pli de la validation croisée. On peut utiliser `GridSearchCV` avec les méthodes de sous-échantillonnage qui prenne du temps à s'éxécuter puisqu'elles n'introduisent pas d'information de l'ensemble d'entraînement dans l'ensemble de test.\n",
    "\n",
    "La fonctionalité `print_metrics_resample` permet d'imprimer une estimation de la performance d'un prédicteur par validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "metrics['accuracy'] = accuracy_score\n",
    "metrics['recall'] = recall_score\n",
    "\n",
    "def grid_search_cv_resample(X_train, y_train, model, params, cv=5, resampler=None, metric='accuracy', verbose=True):\n",
    "    \"\"\"\n",
    "    Returns the best model found by cross validation.\n",
    "    \"\"\"\n",
    "    # Folds are made by preserving the percentage of samples for each class.\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=False)\n",
    "\n",
    "    param_grid = ParameterGrid(params)\n",
    "    best_params = None\n",
    "    best_score = 0\n",
    "    \n",
    "    scoring = metrics[metric]\n",
    "    \n",
    "    time1 = t()\n",
    "    for param_combination in param_grid:\n",
    "        \n",
    "        # Set model parameters\n",
    "        model.set_params(**param_combination)\n",
    "        \n",
    "        scores = []\n",
    "        \n",
    "        # Cross validation\n",
    "        for train_index, val_index in skf.split(X_train, y_train):\n",
    "            \n",
    "            # Train-val split\n",
    "            X_val, y_val = X_train[val_index], y_train[val_index] \n",
    "            X_train_resample, y_train_resample = X_train[train_index], y_train[train_index]\n",
    "            # Re-sample training set\n",
    "            if resampler is not None:\n",
    "                X_train_resample, y_train_resample = resampler.fit_resample(X_train_resample, y_train_resample)\n",
    "            \n",
    "            # Train - predict on validation\n",
    "            model.fit(X_train_resample, y_train_resample)\n",
    "            pred = model.predict(X_val)\n",
    "            \n",
    "            # Evaluate performance\n",
    "            scores.append(scoring(y_val, pred))\n",
    "            # Only report results for the class specified by pos_label (default=1).\n",
    "\n",
    "        score = np.mean(scores)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score, best_params = score, param_combination\n",
    "\n",
    "    time2 = t()\n",
    "    if verbose:\n",
    "        print('\\nBest params', best_params)\n",
    "        print(f'{metric} score:', best_score)\n",
    "        print('Time:', time2-time1)\n",
    "    \n",
    "    return model.set_params(**best_params)\n",
    "\n",
    "\n",
    "def print_metrics_resample(X, y, model, cv=5, resampler=None):\n",
    "    \n",
    "    # Folds are made by preserving the percentage of samples for each class.\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=False)\n",
    "    \n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    support = []\n",
    "    accuracy = []\n",
    "    \n",
    "    # Cross validation\n",
    "    for train_index, val_index in skf.split(X, y):\n",
    "\n",
    "        # Train-val split\n",
    "        X_val, y_val = X[val_index], y[val_index] \n",
    "        X_train_resample, y_train_resample = X[train_index], y[train_index]\n",
    "        # Re-sample training set\n",
    "        if resampler is not None:\n",
    "            X_train_resample, y_train_resample = resampler.fit_resample(X_train_resample, y_train_resample) # Shuffle this ?! \n",
    "\n",
    "        # Train - predict on validation\n",
    "        model.fit(X_train_resample, y_train_resample)\n",
    "        pred = model.predict(X_val)\n",
    "\n",
    "        # Evaluate performance\n",
    "        metrics = precision_recall_fscore_support(y_val, pred, beta=1.0, labels=[0,1], average=None)\n",
    "        precision.append(metrics[0])\n",
    "        recall.append(metrics[1])\n",
    "        f1.append(metrics[2])\n",
    "        support.append(metrics[3])\n",
    "        accuracy.append(accuracy_score(y_val, pred))\n",
    "    \n",
    "    precision = np.mean(precision, axis=0)\n",
    "    recall = np.mean(recall, axis=0)\n",
    "    f1 = np.mean(f1, axis=0)\n",
    "    support = np.mean(support, axis=0)\n",
    "    accuracy = np.mean(accuracy, axis=0)\n",
    "    \n",
    "    print('\\nAccuracy\\t', accuracy)\n",
    "    print('\\nClass\\t\\t 0\\t\\t1')\n",
    "    print('Precision\\t', '%.3f\\t\\t%.3f'% (precision[0], precision[1]))\n",
    "    print('Recall\\t\\t', '%.3f\\t\\t%.3f'% (recall[0], recall[1]))\n",
    "    print('f1\\t\\t', '%.3f\\t\\t%.3f'% (f1[0], f1[1]))\n",
    "    print('Support\\t\\t', '%.3f\\t%.3f'% (support[0], support[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Normalization\"></a>\n",
    "##  5 Normalisation\n",
    "\n",
    "On voudrait normaliser les colonnes `Time` et `Amount` comme pour les colonnes `V1` à `V28`. Le but principal de cette normalisation est d'aider les techniques de convergence utilisées pour l'optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_amount</th>\n",
       "      <th>norm_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.244964</td>\n",
       "      <td>-1.996583</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.342475</td>\n",
       "      <td>-1.996583</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.160686</td>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.140534</td>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.073403</td>\n",
       "      <td>-1.996541</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   norm_amount  norm_time        V1        V2        V3        V4        V5  \\\n",
       "0     0.244964  -1.996583 -1.359807 -0.072781  2.536347  1.378155 -0.338321   \n",
       "1    -0.342475  -1.996583  1.191857  0.266151  0.166480  0.448154  0.060018   \n",
       "2     1.160686  -1.996562 -1.358354 -1.340163  1.773209  0.379780 -0.503198   \n",
       "3     0.140534  -1.996562 -0.966272 -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4    -0.073403  -1.996541 -1.158233  0.877737  1.548718  0.403034 -0.407193   \n",
       "\n",
       "         V6        V7        V8  ...       V20       V21       V22       V23  \\\n",
       "0  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "time = df['Time'].values.reshape(-1, 1)\n",
    "amount = df['Amount'].values.reshape(-1, 1)\n",
    "norm_time = scaler.fit_transform(time)\n",
    "norm_amount = scaler.fit_transform(amount)\n",
    "df.insert(0, 'norm_time', norm_time)\n",
    "df.insert(0, 'norm_amount',norm_amount)\n",
    "df.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Split\"></a>\n",
    "## 6 Séparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344 cas de fraudes dans l'ensemble d'entraînement (0.17254870488152324 %)\n",
      "148 cas de fraudes dans l'ensemble de test (0.17321489179921118 %)\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = df.drop('Class', axis=1), df['Class']\n",
    "\n",
    "# If stratify not None, data is split in a stratified fashion, using this as the class labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size=0.3, random_state=0, stratify=outputs)\n",
    "\n",
    "# Verify if distributions are the same\n",
    "n_train_fraud = y_train.value_counts()[1]\n",
    "n_test_fraud = y_test.value_counts()[1]\n",
    "train_ratio = n_train_fraud/y_train.shape[0] * 100\n",
    "test_ratio = n_test_fraud/y_test.shape[0] * 100\n",
    "print(f'{n_train_fraud} cas de fraudes dans l\\'ensemble d\\'entraînement ({train_ratio} %)')\n",
    "print(f'{n_test_fraud} cas de fraudes dans l\\'ensemble de test ({test_ratio} %)')\n",
    "\n",
    "# Create a new dataframe for training set\n",
    "train_df = X_train.copy()\n",
    "train_df['Class'] = y_train\n",
    "train_df.sample(random_state=0)\n",
    "\n",
    "X_train, y_train = X_train.values, y_train.values\n",
    "X_test, y_test = X_test.values, y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Reg\"></a>\n",
    "## 7 Régression logistique (implémentation naïve)\n",
    "\n",
    "Pour commencer, implémentons naïvement un classifieur simple comme la régression logistique sur la totalité des données sans se préoccuper du débalancement des données. Comme discuté précédemment, on s'attend à ce que le modèle apprenne à prédire la classe 0 trop souvent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Sélection des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:   49.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres: {'C': 10, 'penalty': 'l2'}\n",
      "Meilleur résultat (moyenne des résultats de validation croisée): 0.9992375756661026\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Tuning penalty and regularization using cross validation (5 folds)\n",
    "params = {'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "log_reg_gs= GridSearchCV(log_reg, params, scoring='accuracy', cv=5, verbose=1) # Using accuracy as scoring metric \n",
    "log_reg_gs.fit(X_train, y_train)\n",
    "print('Meilleurs paramètres:', log_reg_gs.best_params_)\n",
    "print('Meilleur résultat (moyenne des résultats de validation croisée):', log_reg_gs.best_score_)\n",
    "log_reg_best = log_reg_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Évaluation sur les données test\n",
    "\n",
    "On estime le pouvoir de généralisation du classifieur sur l'ensemble de test. Bien que le taux de bonnes classification est élevée, le prédicteur n'a su que détecter 63% des fraudes. Ceci confirme notre hypothèse et on voudrait augmenter significativement cette quantité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9994    0.9998    0.9996     85295\n",
      "           1     0.8774    0.6284    0.7323       148\n",
      "\n",
      "    accuracy                         0.9992     85443\n",
      "   macro avg     0.9384    0.8141    0.8659     85443\n",
      "weighted avg     0.9991    0.9992    0.9991     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg_best.fit(X_train, y_train)\n",
    "predictions = log_reg_best.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Us\"></a>\n",
    "## 8 Sous-échantillonnage\n",
    "\n",
    "### 8.1 Sous-échantillonnage aléatoire\n",
    "\n",
    "Le sous-échantillonnage aléatoire consiste à sélectionner aléatoirement des exemples dans la classe majoritaire pour équilibrer les données. \n",
    "\n",
    "Ci-bas les matrices de corrélations du jeu de donnée débalancé et du jeu de donné balancé avec sous-échantillonnage aléatoire. Les corrélations sont plus évidentes dans le jeu de données balancé de sorte que le sous-échantillonnage aléatoire devrait aider les classifieurs à cerner les attributs permettant d'établir une différence entre les classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16bec8ce6d8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make sure we use the subsample in our correlation\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Original unbalanced dataframe\n",
    "unbalanced_df = df.drop([\"Class\"], axis=1)\n",
    "sns.heatmap(unbalanced_df.corr(), ax=ax1)\n",
    "\n",
    "# Balanced dataframe\n",
    "rand_undersampler = RandomUnderSampler(sampling_strategy=1.0, random_state=0)\n",
    "X_us, y_us = rand_undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "balanced_df = pd.DataFrame(X_us)\n",
    "balanced_df.columns = unbalanced_df.columns\n",
    "sns.heatmap(balanced_df.corr(), ax=ax2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1.1 Sélection du modèle \n",
    "\n",
    "Comme le jeu de donné sous-échantillonné est petit, il devrait avoir une grande variabilité. C'est pourquoi il est raisonnable d'essayer des modèles de basse capacité. Un algorithme trop expressif risque de mémoriser le bruit, de surapprendre et de mal généraliser.\n",
    "\n",
    "Le rappel est une mesure de performance naturelle pour choisir les hyperparamètres des modèles lors de la validation croisée puisque l'ensemble de validation est débalancé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params {'C': 1000, 'penalty': 'l2'}\n",
      "recall score: 0.9303069053708439\n",
      "Time: 4.8437159061431885\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Tuning penalty and regularization using cross validation\n",
    "params = {'penalty': ['l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "log_reg_us = grid_search_cv_resample(X_train,\n",
    "                                     y_train,\n",
    "                                     log_reg,\n",
    "                                     params,\n",
    "                                     cv=5,\n",
    "                                     resampler=rand_undersampler,\n",
    "                                     metric='recall',\n",
    "                                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy\t 0.9498605647670519\n",
      "\n",
      "Class\t\t 0\t\t1\n",
      "Precision\t 1.000\t\t0.031\n",
      "Recall\t\t 0.950\t\t0.930\n",
      "f1\t\t 0.974\t\t0.060\n",
      "Support\t\t 39804.000\t68.800\n"
     ]
    }
   ],
   "source": [
    "print_metrics_resample(X_train, y_train, log_reg_us, cv=5, resampler=rand_undersampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params {'C': 1000, 'kernel': 'rbf'}\n",
      "recall score: 0.9331202046035806\n",
      "Time: 18.91001796722412\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svm_rbf = SVC()\n",
    "\n",
    "# Tuning kernel, C, and degree for polynomial kernel\n",
    "params = {'kernel': ['rbf'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "svm_rbf_us = grid_search_cv_resample(X_train,\n",
    "                                     y_train,\n",
    "                                     svm_rbf, \n",
    "                                     params,\n",
    "                                     cv=5,\n",
    "                                     resampler=rand_undersampler,\n",
    "                                     metric='recall',\n",
    "                                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy\t 0.9426676802076932\n",
      "\n",
      "Class\t\t 0\t\t1\n",
      "Precision\t 1.000\t\t0.028\n",
      "Recall\t\t 0.943\t\t0.933\n",
      "f1\t\t 0.970\t\t0.054\n",
      "Support\t\t 39804.000\t68.800\n"
     ]
    }
   ],
   "source": [
    "print_metrics_resample(X_train, y_train, svm_rbf_us, cv=5, resampler=rand_undersampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params {'n_neighbors': 1}\n",
      "recall score: 0.9128303495311169\n",
      "Time: 99.34462881088257\n"
     ]
    }
   ],
   "source": [
    "# knn\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Tuning k\n",
    "params = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "knn_us = grid_search_cv_resample(X_train,\n",
    "                                 y_train,\n",
    "                                 knn,\n",
    "                                 params,\n",
    "                                 cv=5,\n",
    "                                 resampler=rand_undersampler,\n",
    "                                 metric='recall',\n",
    "                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy\t 0.9360766891038759\n",
      "\n",
      "Class\t\t 0\t\t1\n",
      "Precision\t 1.000\t\t0.024\n",
      "Recall\t\t 0.936\t\t0.913\n",
      "f1\t\t 0.967\t\t0.047\n",
      "Support\t\t 39804.000\t68.800\n"
     ]
    }
   ],
   "source": [
    "print_metrics_resample(X_train, y_train, knn_us, cv=5, resampler=rand_undersampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params {'n_estimators': 100}\n",
      "recall score: 0.9128729752770675\n",
      "Time: 14.876211404800415\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rand_forest = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Tuning number of trees\n",
    "params = {'n_estimators': [1, 10, 100, 500]}\n",
    "rand_forest_us = grid_search_cv_resample(X_train,\n",
    "                                         y_train,\n",
    "                                         rand_forest,\n",
    "                                         params,\n",
    "                                         cv=5,\n",
    "                                         resampler=rand_undersampler,\n",
    "                                         metric='recall',\n",
    "                                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy\t 0.9717953071427143\n",
      "\n",
      "Class\t\t 0\t\t1\n",
      "Precision\t 1.000\t\t0.054\n",
      "Recall\t\t 0.972\t\t0.913\n",
      "f1\t\t 0.986\t\t0.101\n",
      "Support\t\t 39804.000\t68.800\n"
     ]
    }
   ],
   "source": [
    "print_metrics_resample(X_train, y_train, rand_forest_us, cv=5, resampler=rand_undersampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les classifieurs donnent tous de bons résultats pour le rappel et le taux de bonnes classifications global. Par contre, pour la classe 1, la précision et le score-f1 sont assez bas.\n",
    "\n",
    "La forêt d'arbres aléatoires a le plus haut taux de bonnes classifications (\\~97%) avec un rappel raisonable (\\~91%) pour la classe des fraudes. Si on se place dans la position d'une institution bancaire qui se satisfait d'un taux de détection de fraude > 90%, mais qui désire limiter absolument le taux de cas non-fraduleux incorrectement classés pour ne pas déranger inutilement sa clientèle, alors la forêt d'arbres aléatoires est le classifieur le plus intéressant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Sous-échantillonnage par centroïdes\n",
    "\n",
    "Il s'agit de performer l'algorithme de K-Moyennes (K-Mean) sur l'ensemble majoritaire pour sélectionner les exemples à conserver.\n",
    "\n",
    "L'algorithme K-moyenne trouve le barycentre des exemples de la classes majoritaires et les exemples les plus éloignés du centroïde sont considérés comme les moins importants de sorte qu'on les retire.\n",
    "\n",
    "Cette méthode s'assure alors de sélectioner des éléments typiques qui devraient bien représenter la classe majoritaire.\n",
    "\n",
    "#### 8.2.1 Sélection des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_undersampler = ClusterCentroids(sampling_strategy='majority', random_state=0)\n",
    "\n",
    "# Perform under-sampling by generating centroids based on clustering methods.\n",
    "X_train_centroid, y_train_centroid = centroid_undersampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'penalty': 'l2'}\n",
      "Meilleur résultat (moyenne des résultats de validation croisée): 0.9360414683169365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "params = {'penalty': ['l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "log_reg = GridSearchCV(log_reg, params, scoring='accuracy', cv=5, verbose=1)\n",
    "log_reg.fit(X_train_centroid, y_train_centroid)\n",
    "print(log_reg.best_params_)\n",
    "print('Meilleur résultat (moyenne des résultats de validation croisée):', log_reg.best_score_)\n",
    "log_reg_centroid = log_reg.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimation (fiable) de la performance avec un ensemble de validation ayant la distribution initiale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_metrics_resample(X_train, y_train, log_reg_centroid, cv=5, resampler=centroid_undersampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Évaluation sur les données test (sous-échantillonnage aléatoire)\n",
    "\n",
    "La régression logistique a un taux de classification acceptable tout en ayant un bon rappel. Co-bas se trouve l'évaluation de son pouvoir de généralisation avec sous-échantillonnage aléatoire sur l'ensemble de test original.\n",
    "\n",
    "Les résultats sont bons et s'accordent à ceux prédits par la validation croisée sur l'ensemble d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Under-sampled training set\n",
    "X_train_rus, y_train_rus = rand_undersampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_reg_us.fit(X_train_rus, y_train_rus)\n",
    "predictions = log_reg_us.predict(X_test)\n",
    "print(classification_report(y_test, predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "disp = plot_confusion_matrix(log_reg_us,\n",
    "                             X_test,\n",
    "                             y_test,\n",
    "                             display_labels=[\"Transaction normale\", \"Fraude\"],\n",
    "                             values_format='.6g',\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize=None)\n",
    "disp.ax_.set_title('Matrice de confusion de la régression logistique avec sous-échantillonnage aléatoire sur l\\'ensemble de test')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_reg = roc_auc_score(y_test, predictions)\n",
    "print('Roc Auc score', roc_auc_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_function = log_reg_us.decision_function(X_test)\n",
    "\n",
    "# ROC curve\n",
    "log_reg_fpr, log_reg_tpr, log_reg_thresholds = roc_curve(y_test, decision_function)\n",
    "\n",
    "plt.title('courbe ROC')\n",
    "plt.plot(log_reg_fpr, log_reg_tpr, label='Régression logistique')\n",
    "plt.xlabel('taux de faux positifs')\n",
    "plt.ylabel('taux de vrais positifs')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall curve\n",
    "plot_precision_recall_curve(log_reg_us, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds = np.arange(0, 100, 10)/100 # For fraud\n",
    "\n",
    "# predictions_proba = log_reg_us.predict_proba(X_test)[:,-1]\n",
    "\n",
    "# for threshold in thresholds:\n",
    "#     # Prediction\n",
    "#     predictions = (predictions_proba >= threshold).astype(int)\n",
    "    \n",
    "#     # Quality \n",
    "#     confusion_m = confusion_matrix(y_test, predictions)\n",
    "#     tn, fp, fn, tp = confusion_m.ravel()\n",
    "#     print('\\nThreshold=', threshold)\n",
    "#     print('Accuracy=', accuracy_score(y_test, predictions))\n",
    "#     print('true positives\\tfalse positives\\tfalse negatives\\ttrue negatives')\n",
    "#     print('%.0f\\t\\t%.0f\\t\\t%.0f\\t\\t%.0f'% (tn, fp, fn, tp))\n",
    "#     print('Precision=', precision_score(y_test, predictions))\n",
    "#     print('Recall=', recall_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Smote\"></a>\n",
    "## 9 Sur-échantillonnage synthétique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 SMOTE\n",
    "\n",
    "Smote [\\[2\\]](#smote) est une méthode de sur-échantillonnage. La classe minoritaire est augmentée en ajoutant des exemples synthétiques sur les lignes séparant les exemples de leurs plus proches voisins. Les exemples synthétiques sont générés en prenant la différence entre l'exemple courant et un de ses plus propres voisins. La différence est multipliée par un nombre aléatoire entre 0 et 1 pour finalement être additionnée à l'exemple considéré. Ceci revient à créer un exemple synthétique le long du segment rejoignant l'exemple de son voisin.\n",
    "<img src=\"https://www.researchgate.net/publication/287601878/figure/fig1/AS:316826589384744@1452548753581/The-schematic-of-NRSBoundary-SMOTE-algorithm.png\" alt=\"Smote\" height=\"400\" width=\"400\">\n",
    "[source](https://www.researchgate.net/publication/287601878/figure/fig1/AS:316826589384744@1452548753581/The-schematic-of-NRSBoundary-SMOTE-algorithm.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='minority', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Tuning penalty and regularization using cross validation\n",
    "params = {'penalty': ['l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "log_reg_smote = grid_search_cv_resample(X_train,\n",
    "                                        y_train,\n",
    "                                        log_reg,\n",
    "                                        params,\n",
    "                                        cv=5,\n",
    "                                        resampler=smote,\n",
    "                                        metric='recall',\n",
    "                                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics_resample(X_train, y_train, log_reg_smote, cv=5, resampler=smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 ADASYN\n",
    "\n",
    "L'idée d'ADASYN est de générer des exemples synthétiques pour les exemples de la classe minoritaire qui sont plus difficiles à apprendre.\n",
    "\n",
    "ADASYN est programmé formellement de la manière suivante [\\[6\\]](#Adasyn). \n",
    "\n",
    "**Données**\n",
    "\n",
    "Un jeu de données d'entraînement $D_{tr}$ avec $m$ exemples ${\\mathbf{x_i}, y_i}$, $i=1,\\ldots, m$ où $\\mathbf{x_i}$ sont les traits caractéristiques des exemples et $y_i$ sont les classes. Soit aussi $m_s$ et $m_l$ le nombre d'exemple respectivement dans la classe minoritaire et dans la classe majoritaire et soit $d_{th}$ le ratio de débalancement minimum désiré.\n",
    "\n",
    "**Procédure**\n",
    "\n",
    "- Calculer le rapport $d = m_s/m_l$.\n",
    "- Si $d<d_{th}$\n",
    "  - Calculer le nombre d'exemples synthétiques qu'il faut générer pour la classe minoritaire: $ G = (m_l - m_s) \\times \\beta$ où $\\beta \\in [0,1]$ est un paramètre spécifié représentant le niveau d'équilibre des classes désiré après avoir généré les exemples.\n",
    "  - Pour chaque exemple $x_i$ dans la classe minoritaire, trouver les $K$ plus proches voisins et calculer le ratio $r_i = \\Delta_i/K$, $i= 1,\\ldots, m_s$ avec $\\Delta_i$ le nombre de plus proches voisins de $x_i$ qui appartiennent à la classe majoritaire. \n",
    "  - Normaliser $r_i$ avec $r_i^* = r_i/\\sum_{i=1}^{m_s}r_i$ de sorte que $r_i^*$ respecte les axiomes d'une densité de probabilité.\n",
    "  - Calculer le nombre d'exemples qui doivent être générés à partir de chaque exemple de la classe minoritaire $x_i$: $g_i = r_i^* \\times G$.\n",
    "  - Pour chaque exemple $x_i$ de la classe minoritaire, générer $g_i$ synthétiques exemples: Faire de $1$ à $g_i$:\n",
    "    - Choisir aléatoirement un exemple de la classe minoritaire $x_{zi}$ parmi les $K$ plus proches voisins de $x_i$ \n",
    "    - Générerer des exemples synthétiques: $s_i = x_i + (x_{zi} - x_i) \\times \\lambda$ où $\\lambda$ est un nombre aléatoire entre $0$ et $1$.\n",
    "\n",
    "ADASYN est en quelque sorte une variante de SMOTE, mais qui ajoute de la variabilité aux exemples synthétiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn = ADASYN(sampling_strategy='minority', random_state=0, n_neighbors=5, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Tuning penalty and regularization using cross validation\n",
    "params = {'penalty': ['l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "log_reg_adasyn = grid_search_cv_resample(X_train,\n",
    "                                         y_train,\n",
    "                                         log_reg,\n",
    "                                         params,\n",
    "                                         cv=5,\n",
    "                                         resampler=adasyn,\n",
    "                                         metric='recall',\n",
    "                                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_metrics_resample(X_train, y_train, log_reg_adasyn, cv=5, resampler=adasyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Évaluation sur les données test (SMOTE)\n",
    "\n",
    "Les résultats sont très similaires à ceux du sous-échantillonnage aléatoire. Le rappel est bon de sorte qu'on sait détecter la majorité des fraudes, mais la précision et le score f1 sont assez bas. \n",
    "\n",
    "La régression logistique avec SMOTE obtient un taux de bonnes classifications remarquable. Sur les données de test, Le rappel de la classe majoritaire s'élève à $98\\%$ et à $91\\%$ pour la classe minoritaire. C'est particulièrement intéressant si on souhaite ne pas bloquer les cartes inutilement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "log_reg_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "predictions = log_reg_smote.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "disp = plot_confusion_matrix(log_reg_smote,\n",
    "                             X_test,\n",
    "                             y_test,\n",
    "                             display_labels=[\"Normal\", \"Fraude\"],\n",
    "                             values_format='.6g',\n",
    "                             cmap=plt.cm.Reds,\n",
    "                             normalize=None)\n",
    "disp.ax_.set_title('Matrice de confusion régression logistique avec SMOTE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_reg_smote = roc_auc_score(y_test, predictions)\n",
    "print('Roc Auc score', roc_auc_reg_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_function = log_reg_smote.decision_function(X_test)\n",
    "\n",
    "# ROC curve\n",
    "log_reg_fpr, log_reg_tpr, log_reg_thresholds = roc_curve(y_test, decision_function)\n",
    "\n",
    "plt.title('courbe ROC')\n",
    "plt.plot(log_reg_fpr, log_reg_tpr, label='Régression logistique')\n",
    "plt.xlabel('taux de faux positifs')\n",
    "plt.ylabel('taux de vrais positifs')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall curve\n",
    "plot_precision_recall_curve(log_reg_smote, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Vae\"></a>\n",
    "## 10 Sur-échantillonnage avec autoencodeur variationnel \n",
    "\n",
    "\n",
    "### 10.1 Théorie\n",
    "\n",
    "Un auto-encodeur est un réseau de neurones entraîné pour reproduire ses entrées. Il composé de deux parties: un encodeur et un décodeur. L'encodeur est généralement un réseau de neurones dont le nombre de neurones des couches internes diminu proportionnellement à la profondeur du réseau jusqu'à une couche cachée **h** plus fine utilisée pour encoder une représentation condensée latente des entrées. Souvent symétrique à l'encodeur, le décodeur produit une reconstruction des entrées à partir de leurs représentations latentes. Le but principal est que l'encodage **h** capture les propriétés caractérisant la donnée d'entrée.\n",
    "\n",
    "L'autoencodeur variationnel (VAE)[\\[7\\]](#Kingma) est une variante de l'autoencodeur utilisé pour générer des données. Le VAE contient deux composantes: le réseau d'inférence approchée $q(z|x)$ (l'encodeur) et le réseau génératif $p_{modèle}(x|z)$ (le décodeur) étant donné $p(z)$. Puisque ces deux composantes sont implémentées par des réseaux de neurones, ces distributions ne peuvent être qu'approximée, c'est pourquoi on dit que le VAE utilise l'inférence approchée apprise. En particulier l'inférence variatonnelle est utile lorsque l'évaluation de l'intégrale pour trouver l'évidence $p(x)$ en marginalisant $p(x,z)$ n'est pas analytique ou requiert un temps exponentiel.\n",
    "\n",
    "$$\n",
    "p(x) = \\int{p(x,z)dz} = \\int{p(x|z)p(z)dz}\n",
    "$$\n",
    "\n",
    "L'inférence variationnelle est utilisée pour approximer la vraie distribution $p(z|x)$ à partir d'une densité modélisée $q(z)$ sur les variables latentes. On utilise la divergence Kullback–Leibler $KL$ pour trouver une densité suffisamment proche de la vraie distribution conditionnelle:\n",
    "\n",
    "$$\n",
    "q^*(z) = argmin_{q(z)} KL( q(z) | p(z|x))\n",
    "$$\n",
    "\n",
    "où \n",
    "\n",
    "\\begin{align*}\n",
    "KL( q(z) | p(z|x)) &= \\mathbb{E}_{q(z)}(ln\\frac{q(z)}{p(z|x)}) \\\\\n",
    "&= \\mathbb{E}_{q(z)}(ln(q(z))) - \\mathbb{E}_{q(z)}(ln(p(z,x))) + ln(p(x)), \\\\\n",
    "\\end{align*}\n",
    "\n",
    "mais ce problème d'optimisation requiert le calcul de l'évidence $ln(p(x))$ qu'on a supposée difficile à calculer. Avec un peu de gymnastique on peut réarranger les termes pour dériver une borne inférieure pour la vraissemblance marginale $p(x)$:\n",
    "\n",
    "\\begin{align*}\n",
    "ln(p(x)) &= KL( q(z) | p(z|x)) + \\mathbb{E}_{q(z)}(ln(p(z,x))) - \\mathbb{E}_{q(z)}(ln(q(z)))\\\\\n",
    "&\\geq \\mathbb{E}_{q(z)}(ln(p(z,x))) - \\mathbb{E}_{q(z)}(ln(q(z))) \\\\\n",
    "&= \\mathbb{E}_{q(z)}(ln(p(x|z))) + \\mathbb{E}_{q(z)}(ln(p(z))) - \\mathbb{E}_{q(z)}(ln(q(z))) \\\\\n",
    "&= \\mathbb{E}_{q(z)}(ln(p(x|z))) - \\mathbb{E}_{q(z)}(ln(\\frac{q(z)}{p(z)})) \\\\\n",
    "&= \\mathbb{E}_{q(z)}(ln(p(x|z))) - KL( q(z) | p(z) ).\n",
    "\\end{align*}\n",
    "\n",
    "Le dernier membre de droite\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{q(z)}(ln(p(x|z))) - KL( q(z) | p(z) ) = \\mathbb{E}_{q(z)}(ln(p(z,x))) - \\mathbb{E}_{q(z)}(ln(q(z))) = \\mathbb{E}_{q(z)}(ln(\\frac{p(z,x)}{q(z)}))\n",
    "$$\n",
    "\n",
    "est appelé la borne inférieure de l'évidence (ELBO) et son opposé est le problème de minimisation original de la divergence $KL$ plus $ln(p(x))$ qui est une constante relativement à $q(z)$. Par conséquent, le problème de minimisation original peut-être remplacé par le problème alternatif de maximisation de ELBO. \n",
    "\n",
    "Comme on voudrait pouvoir reconstruire une entrée $x$ à partir de son encodage latent correspondant $y$, il est raisonable de poser que la distribution du modèle $q(z)$ dépend explicitement de l'entrée $x$.\n",
    "\n",
    "$$\n",
    "q(z) := q(z|x)\n",
    "$$\n",
    "\n",
    "Dès lors, le problème de maximisation ELBO coïncide avec l'architecture de l'autoencodeur variationel. En pratique, on optimise l'estimation de\n",
    "\n",
    "$$\n",
    "ln(p(x|z)) + ln(p(z)) - ln(p(z|x)).\n",
    "$$\n",
    "\n",
    "Dans le cas d'autoencodeurs variationnels gaussiens, les distributions $q(z|x)$ et $p(z)$ sont supposées normales.\n",
    "\n",
    "$$\n",
    "q(z|x) \\sim \\mathcal{N}(\\mu (x), \\sigma^2(x))\\\\\n",
    "p(z) \\sim \\mathcal{N}(0,1)\n",
    "$$\n",
    "\n",
    "Le vecteur $\\mu(x)$ et la matrice diagonale $\\sigma^2(x)$ de dimensions de l'espace latents sont prédits par le réseaux de neurones d'inférence. Pour évaluer ELBO, on peut utiliser le truc de reparamétrisation [\\[7\\]](#Kingma). La variable latente aléatoire $z \\sim q(z|x)$ peut-être reparamétrée en une variable déterministe \n",
    "\n",
    "$$\n",
    "z = g(\\epsilon, x) = \\mu(x) + \\epsilon\\sigma^2(x)\n",
    "$$ \n",
    "\n",
    "avec $\\epsilon$ une variable de bruit auxiliaire tirée d'une gaussienne centrée réduite.\n",
    "\n",
    "Finalement, la fonction de coût associée à notre problème d'optimisation pour entraîner le réseau s'exprime comme\n",
    "\n",
    "$$\n",
    "\\mathcal{L} =  KL( q(z|x) | p(z) ) - \\frac{1}{N}\\sum_1^Nln(p(y|m))\n",
    "$$\n",
    "\n",
    "\n",
    "### 10.2 Implémentation\n",
    "\n",
    "L'implémentation ci-bas est inspirée par un exemple fourni sur TensorFlow [\\[3\\]](#tfVAE) et par l'exemple dans un article Medium [\\[8\\]](#mediumVAE).\n",
    "\n",
    "La distribution $p(z)$ (prior) est une normale centrée réduite de la dimension de l'espace latent. Elle est implémentée avec `MultivariateNormalDiag`. Le vecteur de moyennes nulles est fourni au paramètre `loc` et la matrice de covariances est l'identité (les normales sont indépendantes).\n",
    "\n",
    "L'encodeur est un réseaux de neurones dont le nombre de neurones diminue à chaque couche. On utilise `MultivariateNormalTriL.params_size` pour indiquer les dimensions de la dernière couche régulière complètement connectée du réseau. La dernière couche du réseaux est une couche `MultivariateNormalTril` qui paramétrise le vecteur de moyennes et la matrice triangulaire inférieure de covariances de $q(z|x)$. À cette étape, on ajoute la divergence $KL( q(z|x) | p(z) )$ au calcul de la fonction coût avec `KLDivergenceRegularizer`.\n",
    "\n",
    "Le décodeur est aussi un réseaux de neurones complètement connecté mais sa dernière couche utilise `IndependentNormal` pour générer la sortie. \n",
    "\n",
    "Pour la fonction coût, on doit seulement calculer l'erreur de reconstruction parce que le terme de la divergence KL est spécifié dans l'encodeur. On calcul la log-vraissemblance négative de l'entrée étant donné la sortie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproductibility\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Settings\n",
    "original_dim = X_train.shape[1]\n",
    "input_shape = X_train[0].shape\n",
    "encoded_size = 2\n",
    "\n",
    "# Prior \n",
    "prior = tfpd.MultivariateNormalDiag(\n",
    "        loc=tf.zeros([encoded_size]), # Mu vector\n",
    "        scale_identity_multiplier=1.0) # Scale \n",
    "\n",
    "# Regularizer that adds a KL divergence penalty to the model loss.\n",
    "# Encourage marginal coherence with a unit-MVN (the \"prior\")\n",
    "kl_divergence = tfpl.KLDivergenceRegularizer(prior)\n",
    "\n",
    "# Loss - Negative Log-likelihood\n",
    "neg_log_likelihood = lambda original_input, model_output: -model_output.log_prob(original_input)\n",
    "\n",
    "# Encoder\n",
    "inference_net = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape=input_shape, name='encoder_input'),\n",
    "    tfkl.Dense(20, activation='relu'),\n",
    "    tfkl.Dense(10, activation='relu'),\n",
    "    tfkl.Dense(5, activation='relu'),\n",
    "    # full-covariance Gaussian distribution, \n",
    "    # with its mean and covariance matrices parameterized by the output of a neural network.\n",
    "    tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(encoded_size), activation=None),\n",
    "    # precedent output has a shape: encoded_size + encoded_size * (encoded_size + 1) // 2\n",
    "    tfpl.MultivariateNormalTriL(  # Latent space\n",
    "    encoded_size,\n",
    "    activity_regularizer=kl_divergence)\n",
    "], name='Encoder')\n",
    "\n",
    "# Decoder\n",
    "generative_net = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape=encoded_size, name='decoder_input'),\n",
    "    tfkl.Dense(5, activation='relu'),\n",
    "    tfkl.Dense(10, activation='relu'),\n",
    "    tfkl.Dense(20, activation='relu'),\n",
    "    tfkl.Dense(tfpl.IndependentNormal.params_size(original_dim), activation=None),\n",
    "    tfpl.IndependentNormal(original_dim),\n",
    "], name='Decoder')\n",
    "\n",
    "# Variational auto-encoder\n",
    "vae = tfk.Model(inputs=inference_net.inputs,\n",
    "                outputs=generative_net(inference_net.outputs[0]),\n",
    "                name='Variational_Autoencoder')\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
    "vae.compile(optimizer=optimizer, loss=neg_log_likelihood)\n",
    "\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"model.PNG\" alt=\"model\" style=\"width:400px;height:500px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut que le réseau apprenne la distribution des transactions frauduleuses. C'est pourquoi on l'entraîne exclusivement sur des fraudes. \n",
    "\n",
    "La méthode `from_tensor_slices` découpe les tenseurs en argument selon leur première dimension. Cette opération paire un exemple avec lui même pour calculer l'erreur de reconstruction dans la fonction perte du réseau. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "BATCH_SIZE = 32\n",
    "MAX_EPOCHS = 1000 # for early stopping\n",
    "\n",
    "# Train - Val split for VAE\n",
    "X_train_vae, X_val_vae, y_train_vae, y_val_vae = train_test_split(X_train,\n",
    "                                                                  y_train,\n",
    "                                                                  test_size=0.3,\n",
    "                                                                  random_state=0,\n",
    "                                                                  stratify=y_train)\n",
    "\n",
    "# Training on fraud instances\n",
    "X_fraud_train = X_train_vae[y_train_vae == 1]\n",
    "X_fraud_val = X_val_vae[y_val_vae == 1]\n",
    "\n",
    "tf_train = tf.data.Dataset.from_tensor_slices((X_fraud_train, X_fraud_train)).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE).shuffle(int(10e4))\n",
    "tf_val = tf.data.Dataset.from_tensor_slices((X_fraud_val, X_fraud_val)).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE).shuffle(int(10e4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le défi est d'apprendre la distribution des fraudes, mais en disposant seulement de très peu de données. L'ensemble d'entraînement a une grande variabilité et le modèle risque de sur-ajuster les données d'entraînement. \n",
    "\n",
    "L'arrêt précoce (early stopping) est une forme de régularisation qu'on peut utiliser pour éviter le sur-apprentissage. \n",
    "Cette technique consiste à cesser l'entraînement du modèle lorsque que le coût relatif à l'ensemble de validation n'a pas diminué significativement pour quelques époques, et ce, même si le coût relatif à l'entraînement continu de diminuer. \n",
    "\n",
    "<img src=\"early stopping.PNG\" alt=\"early stopping\" style=\"width:500px;height:350px;\">\n",
    "\n",
    "[Source](#neural)\n",
    "\n",
    "Le nombre d'époques est le nombre de passes de l'algorithme d'optimisation dans l'ensemble d'entraînement. Cette quantité peut-être vue comme un hyperparamètre qui contrôle l'expressivité du modèle. C'est pourquoi l'arrêt précoce a pour effet de ne pas coller trop aux données d'entraînement. Il donne une idée du nombre d'itérations qui peuvent être faites avant de commencer à sur-apprendre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop training when a monitored quantity (here validation loss) has stopped improving.\n",
    "earlystopper = EarlyStopping(monitor='val_loss',\n",
    "                             mode='min',\n",
    "                             min_delta=0.005,\n",
    "                             patience=20, # Training stops when val_loss fails to decrease for 20 consecutive epochs\n",
    "                             verbose=0,\n",
    "                             restore_best_weights=True)\n",
    "\n",
    "# Training\n",
    "hist = vae.fit(tf_train,\n",
    "               epochs=MAX_EPOCHS,\n",
    "               shuffle=True,\n",
    "               verbose=0,\n",
    "               validation_data=tf_val,\n",
    "               callbacks=[earlystopper])\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='best')\n",
    "plt.yscale('log',basey=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme la dimension d'encodage choisie est 2, on peut visualiser les moyennes et les écarts-types modélisés par le réseau d'inférence $q(z|x)$. En regardant les graphiques, on voit que le réseau d'inférence semble distinguer les fraudes des transactions normales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_frauds = X_val_vae[y_val_vae == 1]\n",
    "n_frauds = X_frauds.shape[0]\n",
    "X_non_frauds = X_val_vae[y_val_vae == 0][:n_frauds]\n",
    "q = inference_net(np.concatenate([X_frauds, X_non_frauds]))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# mean\n",
    "plt.subplot(121)\n",
    "latent_mean = q.mean()\n",
    "plt.scatter(latent_mean[:n_frauds, 0], latent_mean[:n_frauds, 1], c='r', marker='x', label='Fraud')\n",
    "plt.scatter(latent_mean[n_frauds:, 0], latent_mean[n_frauds:, 1], c='b', marker='o', label='Normal transaction')\n",
    "plt.legend(loc='best')\n",
    "plt.title('latent means')\n",
    "\n",
    "# std\n",
    "plt.subplot(122)\n",
    "latent_mean = q.stddev()\n",
    "plt.scatter(latent_mean[:n_frauds, 0], latent_mean[:n_frauds, 1], c='r', marker='x', label='Fraud')\n",
    "plt.scatter(latent_mean[n_frauds:, 0], latent_mean[n_frauds:, 1], c='b', marker='o', label='Normal transaction')\n",
    "plt.legend(loc='best')\n",
    "plt.title('latent standard deviation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour générer de nouveaux cas de fraudes, on doit fournir un vecteur aléatoire au model génératif. Comme on a supposé que $p(z)$ est de distribution normale centrée réduite, ce vecteur aléatoire doit ête échantillonné selon cette distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates new examples\n",
    "def sample(generator, encoded_size, n_samples):\n",
    "    z = tf.random.normal(shape=(n_samples, encoded_size))\n",
    "    return generator.predict(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous une visualisation des données originales et des données synthétiques créées par le réseau génératif de l'autoencodeur variationnel. La méthode de réduction de dimensionalité T-sne projette les 30 traits caractéristiques d'une transaction sur 2 composantes pour rendre la visualisation possible.\n",
    "\n",
    "On remarque que les fraudes et les transactions synthétiques générées par le réseau génératif sont dans un même groupement, ce qui suggère que l'autoencodeur variationnel a appris la distribution des fraudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "# Original data \n",
    "plt.subplot(121)\n",
    "\n",
    "X, y = X_train, y_train\n",
    "X_train_fraud= X[y == 1]\n",
    "y_train_fraud = y[y == 1]\n",
    "n_fraud = X_train_fraud.shape[0]\n",
    "X_train_non_fraud = X[y == 0][: n_fraud]\n",
    "y_train_non_fraud = y[y == 0][: n_fraud]\n",
    "X_to_plot = np.concatenate([X_train_fraud, X_train_non_fraud])\n",
    "y_to_plot = np.concatenate([y_train_fraud, y_train_non_fraud])\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "X_tsne = tsne.fit_transform(X_to_plot)\n",
    "\n",
    "plt.scatter(X_tsne[y_to_plot == 0, 0],\n",
    "            X_tsne[y_to_plot == 0, 1],\n",
    "            marker='o',\n",
    "            color='b',\n",
    "            label='Normal transaction')\n",
    "plt.scatter(X_tsne[y_to_plot == 1, 0],\n",
    "            X_tsne[y_to_plot == 1, 1],\n",
    "            marker='x',\n",
    "            color='r',\n",
    "            label='Fraud')\n",
    "plt.title('Groupements pour les données originales avec T-sne')\n",
    "plt.legend(loc='best')\n",
    "plt.axis(False)\n",
    "\n",
    "# Synthetic data\n",
    "plt.subplot(122)\n",
    "\n",
    "original_frauds = X_train[y_train == 1]\n",
    "n_frauds = original_frauds.shape[0]\n",
    "synth_frauds = sample(generative_net, 2, n_frauds)\n",
    "non_frauds = X_train[y_train == 0][: 2*n_frauds]\n",
    "X_to_plot = np.concatenate([original_frauds, synth_frauds, non_frauds])\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "X_tsne = tsne.fit_transform(X_to_plot)\n",
    "\n",
    "plt.scatter(X_tsne[:n_frauds, 0], X_tsne[:n_frauds, 1], marker='x', color='r', label='Fraud')\n",
    "plt.scatter(X_tsne[n_frauds:2*n_frauds, 0], X_tsne[n_frauds:2*n_frauds, 1], marker='x', color='y', label='Synthetic fraud')\n",
    "plt.scatter(X_tsne[2*n_frauds:, 0], X_tsne[2*n_frauds:, 1], marker='o', color='b', label='Normal transaction')\n",
    "plt.title('Groupements avec les données synthétiques')\n",
    "plt.legend(loc='best')\n",
    "plt.axis(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Régression logistique\n",
    "\n",
    "Ci-bas la performance de la régression logistique entraînée avec les exemples synthétiques. À la différence des méthodes précédentes, cette méthode de sur-échantillonnage permet d'avoir une meilleure précision. En effet, bien que le rappel est un peu inférieur pour la classe de fraudes, le score f1 est nettement supérieur. Les performance relatives à la classe de transactions normales sont excellentes, de sorte que cette méthode est favorable si on souhaite ne pas déranger des clients inutilement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = X_train[y_train == 0].shape[0] - X_train[y_train == 1].shape[0]\n",
    "X_synthetic_frauds = sample(generative_net, 2, n_samples)\n",
    "y_synthetic_frauds = np.ones(n_samples)\n",
    "\n",
    "X_train_vae = np.concatenate([X_train, X_synthetic_frauds])\n",
    "y_train_vae = np.concatenate([y_train, y_synthetic_frauds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Tuning penalty and regularization using cross validation (5 folds)\n",
    "params = {'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "# Using accuracy as since the validation set is balanced\n",
    "log_reg = GridSearchCV(log_reg, params, scoring='accuracy', cv=5, verbose=1) \n",
    "log_reg.fit(X_train_vae, y_train_vae)\n",
    "print('Meilleurs paramètres:', log_reg.best_params_)\n",
    "print('Meilleur résultat (moyenne des résultats de validation croisée):', log_reg.best_score_)\n",
    "log_reg_vae = log_reg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_vae.fit(X_train_vae, y_train_vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on test set\n",
    "pred = log_reg_vae.predict(X_test)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 Détection d'anomalies VAE\n",
    "\n",
    "Les auto-encodeurs peuvent être utilisés pour établir directement une classification dans le cadre d'un apprentissage non-supervisé (sans classe).\n",
    "\n",
    "Si un auto-encodeur s'entraîne seulement sur les transactions normales, alors il va apprendre à les reproduire. De là on s'attend à ce qu'il éprouve des difficultés à reproduire fidèlement les cas de fraudes puisque ses poids ont été appris en fonction des transactions normales. Pour cette raison, le coût de reconstruction devrait être élevé pour les fraudes de sorte qu'on peut classifier les transactions en fonction d'un seuil critique du coût de reconstruction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproductibility\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Settings\n",
    "original_dim = X_train.shape[1]\n",
    "input_shape = X_train[0].shape\n",
    "encoded_size = 2\n",
    "\n",
    "# Prior \n",
    "prior = tfpd.MultivariateNormalDiag(\n",
    "        loc=tf.zeros([encoded_size]), # Mu vector\n",
    "        scale_identity_multiplier=1.0) # Scale \n",
    "\n",
    "# Regularizer that adds a KL divergence penalty to the model loss.\n",
    "# Encourage marginal coherence with a unit-MVN (the \"prior\")\n",
    "kl_divergence = tfpl.KLDivergenceRegularizer(prior)\n",
    "\n",
    "# Loss - Negative Log-likelihood\n",
    "neg_log_likelihood = lambda original_input, model_output: -model_output.log_prob(original_input)\n",
    "\n",
    "# Encoder\n",
    "inference_net = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape=input_shape, name='encoder_input'),\n",
    "    tfkl.Dense(20, activation='relu'),\n",
    "    tfkl.Dense(10, activation='relu'),\n",
    "    tfkl.Dense(5, activation='relu'),\n",
    "    # full-covariance Gaussian distribution, \n",
    "    # with its mean and covariance matrices parameterized by the output of a neural network.\n",
    "    tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(encoded_size), activation=None),\n",
    "    tfpl.MultivariateNormalTriL(  # Latent space\n",
    "    encoded_size,\n",
    "    activity_regularizer=kl_divergence)\n",
    "], name='Encoder')\n",
    "\n",
    "# Decoder\n",
    "generative_net = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape=encoded_size, name='decoder_input'),\n",
    "    tfkl.Dense(5, activation='relu'),\n",
    "    tfkl.Dense(10, activation='relu'),\n",
    "    tfkl.Dense(20, activation='relu'),\n",
    "    tfkl.Dense(tfpl.IndependentNormal.params_size(original_dim), activation=None),\n",
    "    tfpl.IndependentNormal(original_dim),\n",
    "], name='Decoder')\n",
    "\n",
    "# Variational auto-encoder\n",
    "vae = tfk.Model(inputs=inference_net.inputs,\n",
    "                outputs=generative_net(inference_net.outputs[0]),\n",
    "                name='Variational_Autoencoder')\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
    "vae.compile(optimizer=optimizer, loss=neg_log_likelihood)\n",
    "\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - val - split \n",
    "X_train_fraud, X_train_norm = X_train[y_train == 1], X_train[y_train == 0]\n",
    "\n",
    "X_train_vae, X_val_vae = train_test_split(X_train_norm, test_size=0.3, shuffle=False)\n",
    "\n",
    "# We can add the remaining frauds to the test set \n",
    "# Todo\n",
    "\n",
    "print(X_train_vae.shape, X_val_vae.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "max_epochs = 1000\n",
    "tf_train = tf.data.Dataset.from_tensor_slices((X_train_vae, X_train_vae)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE).shuffle(int(10e4))\n",
    "tf_val = tf.data.Dataset.from_tensor_slices((X_val_vae, X_val_vae)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE).shuffle(int(10e4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "earlystopper = EarlyStopping(monitor='val_loss',\n",
    "                             mode='min',\n",
    "                             min_delta=0.005,\n",
    "                             patience=20,\n",
    "                             verbose=0,\n",
    "                             restore_best_weights=True)\n",
    "\n",
    "hist = vae.fit(tf_train,\n",
    "               epochs=max_epochs,\n",
    "               shuffle=True,\n",
    "               verbose=0,\n",
    "               validation_data=tf_val,\n",
    "               callbacks=[earlystopper])\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='best')\n",
    "plt.yscale('log',basey=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme mentionné précédemment, pour pouvoir classifier, il faut définir une métrique pour quantifier l'erreur ou le coût de reconstruction à la sortie de l'autoencodeur variationnel.\n",
    "\n",
    "La fonction suivante retourne la probabilité que la sortie du réseau soit générée par son entrée. Une probabilité de reconstruction élevée devrait correspondre à une transaction normale tandis qu'une faible probabilité de reconstruction devrait correspondre à une fraude parce que les poids du réseaux sont optimisés en fonction des transactions normales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_prob(X, n_samples):\n",
    "    # Multivariate Normal \n",
    "    encoder_out = inference_net(X) # Output tensor, .predict() outputs a numpy array\n",
    "    # Sample n_samples from this distribution\n",
    "    encoder_samples = encoder_out.sample(n_samples)\n",
    "    # Generate new example from theses random samples \n",
    "    generated_examples = generative_net(encoder_samples)\n",
    "    # Log probability (and not .prob to avoid floating arithmetic error) density/mass function.\n",
    "    reconstruction_log_prob = np.mean(generated_examples.log_prob(X), axis=0)\n",
    "    return reconstruction_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of sampled examples of the triangular Gaussian for each input.\n",
    "n_samples = 10  # For stability\n",
    "\n",
    "reconstruction_log_prob = reconstruction_prob(X_test, n_samples)\n",
    "\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, -reconstruction_log_prob)\n",
    "auc = roc_auc_score(y_test, -reconstruction_log_prob)\n",
    "\n",
    "plt.plot(fp_rate,tp_rate,label=\"linear in-sample, auc=\"+str(auc))\n",
    "plt.title('VAE roc curve - test')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour déterminer un seuil pour la classification en fonction de la probabilité de reconstruction, on peut utiliser une méthode basée sur la cote Z, mais qui utilise la médiane (MAD) plutôt que la moyenne pour éviter que les anomalies influencent elles-même la métrique par rapport à laquelle elles seront choisies. \n",
    "\n",
    "Soit $m$ la médiane. On appelle $MAD$ la médiane de la différence en valeur absolue entre les point $x_i$ et $m$\n",
    "\n",
    "$$\n",
    "MAD = médianne\\{|x_i-m|\\}.\n",
    "$$\n",
    "\n",
    "Pour un point $x_i$, on calcule sa cote Z modifiée de la façon suivante:\n",
    "\n",
    "$$\n",
    "    Z_i = \\frac{0.6745(x_i - m)}{MAD}.\n",
    "$$\n",
    "\n",
    "La quantité $0.6745$ représente le $75$e quartile d'une distribution normale (MAD converge vers cette distribution). \n",
    "\n",
    "Contrairement aux méthodes basées sur les centiles, la cote Z modifiée a l'avantage d'être indépendante du nombre de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implentation is inspired by this notebook https://www.kaggle.com/robinteuwens/anomaly-detection-with-auto-encoders\n",
    "def compute_mad_z_scores(points):  \n",
    "    m = np.median(points, axis=0)\n",
    "    abs_deviation = np.abs(points - m)\n",
    "    m_abs_deviation = np.median(abs_deviation)\n",
    "    modified_z_score = 0.6745 * abs_deviation / m_abs_deviation\n",
    "    return modified_z_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_SCORE_THRESHOLD = 2.5\n",
    "mad_z_scores = compute_mad_z_scores(-reconstruction_log_prob)\n",
    "mad_outliers = (mad_z_scores > Z_SCORE_THRESHOLD).astype(int)\n",
    "n_outliers = len(mad_outliers[mad_outliers==True])\n",
    "print(f'This results in {n_outliers:,} detected anomalies, or {n_outliers/len(y_test)*100:.2f}% out of {len(y_test):,} trades reported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La performance sur les données tests est inférieure à celle obtenue précédemment avec l'apprentissage supervisé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# get (mis)classification\n",
    "cm = confusion_matrix(y_test, mad_outliers)\n",
    "print(f'The classifications using the MAD method with threshold={Z_SCORE_THRESHOLD} are as follows:\\n{cm}\\n')\n",
    "print(f'Fraud caught successfully (recall):\\n{cm[1,1]} / ({cm[1,0]} + {cm[1,1]}) = {cm[1,1] / (cm[1,0] + cm[1,1]) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, mad_outliers, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Références\n",
    "\n",
    "[1] Blei, D., Kucukelbir, A. et McAuliffe, J. (2018). Variational Inference: A Review for Statisticians. arXiv:1601.00670.\n",
    "\n",
    "<a id=\"smote\"></a>\n",
    "[2] Chawla, N., Bowyer, K., Hall, L. et Kegelmeyer, P. (2002). SMOTE: Synthetic Minority Over-sampling Technique. arXiv:1106.1813.\n",
    "\n",
    "<a id=\"tfVAE\"></a>\n",
    "[3] Convolutional Variational Autoencoder. TensorFlow. https://www.tensorflow.org/tutorials/generative/cvae\n",
    "\n",
    "[4] Fajardo, V., Findlay, D., Houmanfar, R., Jaiswal, C., Liang, J. et Xie, H. (2018). VOS: a Method for Variational Oversampling of Imbalanced Data. arXiv:1809.02596.\n",
    "\n",
    "<a id=\"neural\"></a>\n",
    "[5] Guillaume, R. (2019). IFT3395 : Neural Networks \\[notes de cours\\]. StudiUM. https://studium.umontreal.ca/\n",
    "\n",
    "<a id=\"Adasyn\"></a>\n",
    "[6] Haibo H., Yang B., Edwardo A. G., et Shutao L. (2008). ADASYN: Adaptive Synthetic Sampling Approach for Imbalanced Learning\n",
    "\n",
    "<a id=\"Kingma\"></a>\n",
    "[7] Kingma, D. et Welling, M. (2014). Auto-Encoding Variational Bayes. arXiv:1312.6114.\n",
    "\n",
    "<a id=\"mediumVAE\"></a>\n",
    "[8] TFP Team. (2019).Variational Autoencoders with Tensorflow Probability Layers. Medium\n",
    "https://medium.com/tensorflow/variational-autoencoders-with-tensorflow-probability-layers-d06c658931b7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
