{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection de fraudes de cartes de crédit\n",
    "\n",
    "## Introduction\n",
    "\n",
    "L'objectif du projet consiste en l'élaboration d'algorithmes de classification capables de détecter les transactions frauduleuses dans un dataset kaggle de transactions de cartes de crédit. Les données peuvent être trouvées [ici](https://www.kaggle.com/mlg-ulb/creditcardfraud).\n",
    "\n",
    "Les cas de fraudes ne représentant que 0.173% du nombre total de transactions, l’implémentation des modèles et les métriques de mesures de performance utilisées doivent être adaptées aux données fortement débalancées. Il est également souhaitable que la classification soit sensible, c’est-à-dire que le taux des faux positifs soit minimal, puisque l'institution bancaire ne veut pas déranger inutilement ses clients.\n",
    "\n",
    "\n",
    "## Plan\n",
    "\n",
    "* Exploration des données\n",
    "  * Fléau des données débalancées\n",
    "* Prétraitement\n",
    "  * Normalisation\n",
    "  * Séparation du data\n",
    "* Régression logistique\n",
    "* Undersampling aléatoire\n",
    "  * Sélection de modèle\n",
    "  * Évaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des données\n",
    "\n",
    "Le dataset contient 284 807 exemples ayant chacun 31 traits caractéristiques numériques dont le temps et le montant de la transaction. Les 28 autres proviennent d'une analyse en composante principale (PCA) effectuée pour anonymiser les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (284807, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/creditcard.csv\")\n",
    "print('shape: ', df.shape)\n",
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les exemples non-frauduleux sont étiquetés par la classe 0 et les exemples frauduleux par la classe 1. Seulement 492 (0.173%) des exemples sont de la classe 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de fraudes: 492\n",
      "Taux de fraudes: 0.173 %\n"
     ]
    }
   ],
   "source": [
    "fraud_count = df['Class'].value_counts()[1]\n",
    "fraud_ratio = np.around(fraud_count/len(df)*100, 3)\n",
    "print(\"Nombre de fraudes:\", fraud_count)\n",
    "print(\"Taux de fraudes:\", fraud_ratio, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Fléau des données fortement débalancées\n",
    "\n",
    "Les données sont extrèmements débalancées. Le classifieur risque de mémoriser que les données sont débalancées et d'assumer que la majorité des exemples sont des cas non-frauduleux (sur-apprentissage) plutôt que de détecter les liens dans les traits caractéristiques permettant réellement de déterminer si une transaction est une fraude.\n",
    "\n",
    "Les cas de fraudes ne représentant que 0.172% du nombre total de transactions, l’implémentation des modèles et les métriques de mesures de performance utilisées devront être adaptées aux données fortement débalancées. En effet, le taux de classifications (accuracy) n'est pas une mesure de performance naturelle lorsque les données sont débalancées. Pour l'illustrer, considérons un classifieur qui prédit la classe '0' à tous les nouveaux exemples de tests. Un tel classifieur obtiendrait un taux de classifications correctes de 99.827% sans détecter aucune fraude. Un tel classifieur est incapable de généraliser, même si son taux de classifications est élevé.\n",
    "\n",
    "D'autres métriques sont plus naturelles pour évaluer la performance d'un dataset débalancé. \n",
    "\n",
    "Soit $N$ le nombre total d'exemples.\n",
    "\n",
    "vrais positifs (VP): \n",
    "\n",
    "faux positifs (FP): \n",
    "\n",
    "vrais négatifs (VN):\n",
    "\n",
    "faux négaitfs (FN):\n",
    "\n",
    "Accuracy $:=\\frac{VP+VN}{N}$\n",
    "\n",
    "Precision $:=\\frac{VP}{VP+FP}$\n",
    "\n",
    "Recall $:=\\frac{VP}{VP+FN}$\n",
    "\n",
    "f1-score $:=2\\ \\frac{\\text{precision}\\ \\times\\ \\text{recall}}{\\text{precision}\\ +\\ \\text{recall}}$\n",
    "\n",
    "Support:\n",
    "\n",
    "Le recall nous est particulièrement intéressant comme il s'agit le taux de fraudes détectées.\n",
    "\n",
    "\"Many machine-learning techniques, such as neural networks, make more reliable predictions from being trained with balanced data. Certain analytical methods, however, notably linear regression and logistic regression, do not benefit from a balancing approach.\" (Wikipedia)\n",
    "\n",
    "Dotons-nous d'une fonction pour imprimer ces métriques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_true, y_pred, title=''):\n",
    "    print(title,'\\n')\n",
    "    print('Accuracy:', accuracy_score(y_true, y_pred))\n",
    "    confusion_m = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_m.ravel()\n",
    "    \n",
    "    print('\\ntrue positives\\tfalse positives\\tfalse negatives\\ttrue negatives')\n",
    "    print('%.0f\\t\\t%.0f\\t\\t%.0f\\t\\t%.0f'% (tn, fp, fn, tp))\n",
    "\n",
    "    metrics = precision_recall_fscore_support(y_true, y_pred, beta=1.0)\n",
    "    precision = metrics[0]\n",
    "    recall = metrics[1]\n",
    "    f1 = metrics[2]\n",
    "    support = metrics[3]\n",
    "    print('\\nClass\\t\\t 0\\t\\t1')\n",
    "    print('Precision\\t', '%.2f\\t\\t%.2f'% (precision[0], precision[1]))\n",
    "    print('recall\\t\\t', '%.2f\\t\\t%.2f'% (recall[0], recall[1]))\n",
    "    print('f1\\t\\t', '%.2f\\t\\t%.2f'% (f1[0], f1[1]))\n",
    "    print('support\\t\\t', '%.2f\\t%.2f'% (support[0], support[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-traitement\n",
    "\n",
    "### Normalisation\n",
    "On voudrait normaliser les colonnes Time et Amount comme pour les colonnes V1 à V28. Le but principal de cette normalisation est d'aider les techniques de convergences utilisées pour l'optimisation.\n",
    "\n",
    "<span style=\"color:red\">Essayer: RobustScaler Scale features using statistics that are robust to outliers.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_amount</th>\n",
       "      <th>norm_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.244964</td>\n",
       "      <td>-1.996583</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.342475</td>\n",
       "      <td>-1.996583</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.160686</td>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.140534</td>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.073403</td>\n",
       "      <td>-1.996541</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   norm_amount  norm_time        V1        V2        V3        V4        V5  \\\n",
       "0     0.244964  -1.996583 -1.359807 -0.072781  2.536347  1.378155 -0.338321   \n",
       "1    -0.342475  -1.996583  1.191857  0.266151  0.166480  0.448154  0.060018   \n",
       "2     1.160686  -1.996562 -1.358354 -1.340163  1.773209  0.379780 -0.503198   \n",
       "3     0.140534  -1.996562 -0.966272 -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4    -0.073403  -1.996541 -1.158233  0.877737  1.548718  0.403034 -0.407193   \n",
       "\n",
       "         V6        V7        V8  ...       V20       V21       V22       V23  \\\n",
       "0  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "time = df['Time'].values.reshape(-1, 1)\n",
    "amount = df['Amount'].values.reshape(-1, 1)\n",
    "norm_time = scaler.fit_transform(time)\n",
    "norm_amount = scaler.fit_transform(amount)\n",
    "df.insert(0, 'norm_time', norm_time)\n",
    "df.insert(0, 'norm_amount',norm_amount)\n",
    "df.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation du data\n",
    "\n",
    "Avant de sélectionner des modèles, on sépare les données en ensembles d'entraînement et de tests.\n",
    "\n",
    "Comme les cas de fraudes sont sous-représentés, on voudrait s'assurer que les ensembles de tests et d'entraînements suivent la même distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio de fraudes (Train): 0.17254870488152324\n",
      "Ratio de fraudes (Test): 0.17321489179921118\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs, outputs = df.drop('Class', axis=1), df['Class']\n",
    "\n",
    "# If stratify not None, data is split in a stratified fashion, using this as the class labels.\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size=0.3, random_state=0, stratify=outputs)\n",
    "\n",
    "# Verify if distributions are the same\n",
    "print('Ratio de fraudes (Train):', y_train.value_counts()[1]/y_train.shape[0] * 100)\n",
    "print('Ratio de fraudes (Test):', y_test.value_counts()[1]/y_test.shape[0] * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression logistique \n",
    "\n",
    "Pour commencer, essayons d'implémenter naïvement un classifieur simple comme la régression logistique sur la totalité des données. On utilise le taux de bonnes classifications (accuracy) comme mesure de performance.\n",
    "\n",
    "Comme discutter précédemment, on s'attend à ce que le modèle mémorise à tord le débalancement dans les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres: {'C': 1, 'penalty': 'l2'}\n",
      "Meilleur résultat (moyenne des résultats de validation croisée): 0.9992375754900584\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Tuning penalty and regularization using cross validation\n",
    "params = {'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "log_reg_gs= GridSearchCV(log_reg, params, scoring='accuracy', cv=5, verbose=1) # Using accuracy as scoring metric \n",
    "log_reg_gs.fit(X_train, y_train)\n",
    "print('Meilleurs paramètres:', log_reg_gs.best_params_)\n",
    "print('Meilleur résultat (moyenne des résultats de validation croisée):', log_reg_gs.best_score_)\n",
    "log_reg_best = log_reg_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Régression logistique sur les données débalancées \n",
      "\n",
      "Accuracy: 0.999204147794436\n",
      "\n",
      "true positives\tfalse positives\tfalse negatives\ttrue negatives\n",
      "85282\t\t13\t\t55\t\t93\n",
      "\n",
      "Class\t\t 0\t\t1\n",
      "Precision\t 1.00\t\t0.88\n",
      "recall\t\t 1.00\t\t0.63\n",
      "f1\t\t 1.00\t\t0.73\n",
      "support\t\t 85295.00\t148.00\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set \n",
    "predictions = log_reg_best.predict(X_test)\n",
    "\n",
    "print_metrics(y_test, predictions, 'Régression logistique sur les données débalancées')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien que le taux de bonnes classifications semble élevé, le prédicteur n'a su que détecter 0,63% des fraudes. On voudrait augmenter significativement cette quantité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling aléatoire\n",
    "\n",
    "L'idée est d'entraîner un modèle sur un ensemble de données balancé tel quel 50% des données sont des fraudes. Modifier ainsi les données d'entraînement introduit un biais qui sert à compenser le risque de surapprentissage dû au fléau des données débalancées.\n",
    "\n",
    "On sélectionne aléatoirement des données de fraudes et on fait un nouveau dataframe sur lequel on entraîne les modèles. On testera ensuite la performance du modèle le plus performant sur l'ensemble de test original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Try RandomUnderSampler class from the imblearn library. It works by performing k-means clustering on the majority class and removing data points from high-density centroids.</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_amount</th>\n",
       "      <th>norm_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>984.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.137474</td>\n",
       "      <td>-0.102755</td>\n",
       "      <td>-2.381699</td>\n",
       "      <td>1.791634</td>\n",
       "      <td>-3.533385</td>\n",
       "      <td>2.291523</td>\n",
       "      <td>-1.636010</td>\n",
       "      <td>-0.706594</td>\n",
       "      <td>-2.733345</td>\n",
       "      <td>0.273733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223246</td>\n",
       "      <td>0.374509</td>\n",
       "      <td>0.005938</td>\n",
       "      <td>-0.029925</td>\n",
       "      <td>-0.044728</td>\n",
       "      <td>0.007023</td>\n",
       "      <td>0.021970</td>\n",
       "      <td>0.083123</td>\n",
       "      <td>0.027694</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.438511</td>\n",
       "      <td>1.031471</td>\n",
       "      <td>5.534952</td>\n",
       "      <td>3.779761</td>\n",
       "      <td>6.229667</td>\n",
       "      <td>3.210994</td>\n",
       "      <td>4.213735</td>\n",
       "      <td>1.727820</td>\n",
       "      <td>5.907376</td>\n",
       "      <td>4.877936</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166960</td>\n",
       "      <td>2.805378</td>\n",
       "      <td>1.171909</td>\n",
       "      <td>1.210304</td>\n",
       "      <td>0.566407</td>\n",
       "      <td>0.685655</td>\n",
       "      <td>0.477104</td>\n",
       "      <td>1.002104</td>\n",
       "      <td>0.438657</td>\n",
       "      <td>0.500254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.353229</td>\n",
       "      <td>-1.996267</td>\n",
       "      <td>-30.552380</td>\n",
       "      <td>-24.426864</td>\n",
       "      <td>-31.103685</td>\n",
       "      <td>-4.559620</td>\n",
       "      <td>-22.105532</td>\n",
       "      <td>-6.406267</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-41.044261</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.128186</td>\n",
       "      <td>-22.797604</td>\n",
       "      <td>-8.887017</td>\n",
       "      <td>-19.254328</td>\n",
       "      <td>-2.028024</td>\n",
       "      <td>-4.781606</td>\n",
       "      <td>-1.425404</td>\n",
       "      <td>-7.263482</td>\n",
       "      <td>-2.501568</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.346073</td>\n",
       "      <td>-0.989567</td>\n",
       "      <td>-2.859468</td>\n",
       "      <td>-0.170459</td>\n",
       "      <td>-5.120349</td>\n",
       "      <td>-0.081205</td>\n",
       "      <td>-1.848596</td>\n",
       "      <td>-1.587624</td>\n",
       "      <td>-3.105154</td>\n",
       "      <td>-0.218122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184283</td>\n",
       "      <td>-0.174020</td>\n",
       "      <td>-0.524264</td>\n",
       "      <td>-0.245715</td>\n",
       "      <td>-0.373302</td>\n",
       "      <td>-0.358864</td>\n",
       "      <td>-0.283741</td>\n",
       "      <td>-0.069619</td>\n",
       "      <td>-0.062732</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.273468</td>\n",
       "      <td>-0.241542</td>\n",
       "      <td>-0.739646</td>\n",
       "      <td>0.996230</td>\n",
       "      <td>-1.337719</td>\n",
       "      <td>1.360733</td>\n",
       "      <td>-0.488647</td>\n",
       "      <td>-0.616944</td>\n",
       "      <td>-0.635814</td>\n",
       "      <td>0.144982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037463</td>\n",
       "      <td>0.158980</td>\n",
       "      <td>0.036853</td>\n",
       "      <td>-0.031421</td>\n",
       "      <td>0.009163</td>\n",
       "      <td>0.035358</td>\n",
       "      <td>-0.032957</td>\n",
       "      <td>0.051544</td>\n",
       "      <td>0.035099</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.053826</td>\n",
       "      <td>0.904967</td>\n",
       "      <td>1.013464</td>\n",
       "      <td>2.785561</td>\n",
       "      <td>0.347377</td>\n",
       "      <td>4.250632</td>\n",
       "      <td>0.486563</td>\n",
       "      <td>0.126612</td>\n",
       "      <td>0.359971</td>\n",
       "      <td>0.853411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445619</td>\n",
       "      <td>0.672158</td>\n",
       "      <td>0.560266</td>\n",
       "      <td>0.212723</td>\n",
       "      <td>0.359511</td>\n",
       "      <td>0.395077</td>\n",
       "      <td>0.315862</td>\n",
       "      <td>0.454884</td>\n",
       "      <td>0.214626</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.177356</td>\n",
       "      <td>1.640120</td>\n",
       "      <td>2.383325</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>3.183450</td>\n",
       "      <td>12.114672</td>\n",
       "      <td>11.095089</td>\n",
       "      <td>7.769639</td>\n",
       "      <td>12.614867</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>...</td>\n",
       "      <td>15.519527</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>8.361985</td>\n",
       "      <td>5.466230</td>\n",
       "      <td>3.641635</td>\n",
       "      <td>2.208209</td>\n",
       "      <td>2.745261</td>\n",
       "      <td>3.052358</td>\n",
       "      <td>1.779364</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       norm_amount   norm_time          V1          V2          V3  \\\n",
       "count   984.000000  984.000000  984.000000  984.000000  984.000000   \n",
       "mean      0.137474   -0.102755   -2.381699    1.791634   -3.533385   \n",
       "std       1.438511    1.031471    5.534952    3.779761    6.229667   \n",
       "min      -0.353229   -1.996267  -30.552380  -24.426864  -31.103685   \n",
       "25%      -0.346073   -0.989567   -2.859468   -0.170459   -5.120349   \n",
       "50%      -0.273468   -0.241542   -0.739646    0.996230   -1.337719   \n",
       "75%       0.053826    0.904967    1.013464    2.785561    0.347377   \n",
       "max      30.177356    1.640120    2.383325   22.057729    3.183450   \n",
       "\n",
       "               V4          V5          V6          V7          V8  ...  \\\n",
       "count  984.000000  984.000000  984.000000  984.000000  984.000000  ...   \n",
       "mean     2.291523   -1.636010   -0.706594   -2.733345    0.273733  ...   \n",
       "std      3.210994    4.213735    1.727820    5.907376    4.877936  ...   \n",
       "min     -4.559620  -22.105532   -6.406267  -43.557242  -41.044261  ...   \n",
       "25%     -0.081205   -1.848596   -1.587624   -3.105154   -0.218122  ...   \n",
       "50%      1.360733   -0.488647   -0.616944   -0.635814    0.144982  ...   \n",
       "75%      4.250632    0.486563    0.126612    0.359971    0.853411  ...   \n",
       "max     12.114672   11.095089    7.769639   12.614867   20.007208  ...   \n",
       "\n",
       "              V20         V21         V22         V23         V24         V25  \\\n",
       "count  984.000000  984.000000  984.000000  984.000000  984.000000  984.000000   \n",
       "mean     0.223246    0.374509    0.005938   -0.029925   -0.044728    0.007023   \n",
       "std      1.166960    2.805378    1.171909    1.210304    0.566407    0.685655   \n",
       "min     -4.128186  -22.797604   -8.887017  -19.254328   -2.028024   -4.781606   \n",
       "25%     -0.184283   -0.174020   -0.524264   -0.245715   -0.373302   -0.358864   \n",
       "50%      0.037463    0.158980    0.036853   -0.031421    0.009163    0.035358   \n",
       "75%      0.445619    0.672158    0.560266    0.212723    0.359511    0.395077   \n",
       "max     15.519527   27.202839    8.361985    5.466230    3.641635    2.208209   \n",
       "\n",
       "              V26         V27         V28       Class  \n",
       "count  984.000000  984.000000  984.000000  984.000000  \n",
       "mean     0.021970    0.083123    0.027694    0.500000  \n",
       "std      0.477104    1.002104    0.438657    0.500254  \n",
       "min     -1.425404   -7.263482   -2.501568    0.000000  \n",
       "25%     -0.283741   -0.069619   -0.062732    0.000000  \n",
       "50%     -0.032957    0.051544    0.035099    0.500000  \n",
       "75%      0.315862    0.454884    0.214626    1.000000  \n",
       "max      2.745261    3.052358    1.779364    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a random sample of non-fraud exemples\n",
    "fraud_df = df[df['Class']==1]\n",
    "non_fraud_df = df[df['Class']==0]\n",
    "rdm_non_fraud_df = non_fraud_df.sample(n=fraud_df.shape[0])\n",
    "\n",
    "# New balanced df\n",
    "under_sample_df = pd.concat([fraud_df, rdm_non_fraud_df])\n",
    "under_sample_df = under_sample_df.sample(frac=1)\n",
    "\n",
    "under_sample_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque une augmentation des variances pour les paramètres V1 à V28."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélection de modèle\n",
    "\n",
    "Peut-être devrait-on choisir une classe de fonction relativement peu expressive (basse capacité) parce que notre dataset n'a que 984 exemples, ce qui signifie qu'il a une grande variabilité. Un algorithme trop expressif risque de mémoriser le bruit et de surapprendre.\n",
    "\n",
    "Pour augmenter le taux de fraudes détectées, on utilise la métrique recall pour sélectionner le modèle.\n",
    "\n",
    "Essayons quelques modèles linéaires comme la régression logistique et la machine à vecteurs de support ainsi que KNN (un peu plus expressif). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split undersample (us) data \n",
    "inputs, outputs = under_sample_df.drop('Class', axis=1), under_sample_df['Class'] \n",
    "X_train_us, X_test_us, y_train_us, y_test_us = train_test_split(inputs, outputs, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001, 'penalty': 'l2'}\n",
      "Meilleur résultat (moyenne des résultats de validation croisée): 0.9675530095759233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:    7.0s finished\n",
      "C:\\Users\\pasca\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log_reg_us = LogisticRegression()\n",
    "\n",
    "# Tuning penalty and regularization using cross validation\n",
    "params = {'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "log_reg_us_gs= GridSearchCV(log_reg_us, params, scoring='recall', cv=5, verbose=1)\n",
    "log_reg_us_gs.fit(X_train_us, y_train_us)\n",
    "print(log_reg_us_gs.best_params_)\n",
    "print('Meilleur résultat (moyenne des résultats de validation croisée):', log_reg_us_gs.best_score_)\n",
    "log_reg_us_best = log_reg_us_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a probablement augmenté notre capacité à détecter des fraudes avec un recall de 0.95 peut-être au détriment de la précision et de l'Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "{'C': 100}\n",
      "Meilleur résultat (moyenne des résultats de validation croisée): 0.9469036486514077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "# SVM with gaussian kernel\n",
    "svm_rbf_us = SVC(kernel='rbf')\n",
    "\n",
    "# Tuning C\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "svm_rbf_us_gs = GridSearchCV(svm_rbf_us, params, scoring='recall', cv=5, verbose=1)\n",
    "svm_rbf_us_gs.fit(X_train_us, y_train_us)\n",
    "print(svm_rbf_us_gs.best_params_)\n",
    "print('Meilleur résultat (moyenne des résultats de validation croisée):', svm_rbf_us_gs.best_score_)\n",
    "svm_rbf_us_best = svm_rbf_us_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "{'C': 10, 'degree': 2}\n",
      "Meilleur résultat (moyenne des résultats de validation croisée): 0.917405108520326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 210 out of 210 | elapsed:    3.6s finished\n",
      "C:\\Users\\pasca\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# SVM with polynomial kernel\n",
    "svm_poly_us = SVC(kernel='poly')\n",
    "\n",
    "# Tuning C and degree\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'degree': [0, 1, 2, 3, 4, 5]}\n",
    "svm_poly_us_gs = GridSearchCV(svm_poly_us, params, scoring='recall', cv=5, verbose=1)\n",
    "svm_poly_us_gs.fit(X_train_us, y_train_us)\n",
    "print(svm_poly_us_gs.best_params_)\n",
    "print('Meilleur résultat (moyenne des résultats de validation croisée):', svm_poly_us_gs.best_score_)\n",
    "svm_poly_us_best = svm_poly_us_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "{'n_neighbors': 1}\n",
      "Meilleur résultat (moyenne des résultats de validation croisée): 0.9144560201727342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "KNN_us = KNeighborsClassifier()\n",
    "\n",
    "# Tuning k\n",
    "params = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "KNN_us_gs = GridSearchCV(KNN_us, params, scoring='recall', cv=5, verbose=1)\n",
    "KNN_us_gs.fit(X_train_us, y_train_us)\n",
    "print(KNN_us_gs.best_params_)\n",
    "print('Meilleur résultat (moyenne des résultats de validation croisée):', KNN_us_gs.best_score_)\n",
    "KNN_us_gs_best = KNN_us_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 500}\n",
      "Meilleur résultat (moyenne des résultats de validation croisée): 0.9056062029115707\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rand_forest_us = RandomForestClassifier()\n",
    "\n",
    "# Tuning number of trees\n",
    "params = {'n_estimators':[1, 10, 100, 500]}\n",
    "rand_forest_us_gs = GridSearchCV(rand_forest_us, params, scoring='recall', cv=5, verbose=1)\n",
    "rand_forest_us_gs.fit(X_train_us, y_train_us)\n",
    "print(rand_forest_us_gs.best_params_)\n",
    "print('Meilleur résultat (moyenne des résultats de validation croisée):', rand_forest_us_gs.best_score_)\n",
    "rand_forest_us_gs_best = rand_forest_us_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La régression logistique a les meilleures performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.865547792095315 \n",
      "\n",
      "régression logistique avec sub-sample aléatoire \n",
      "\n",
      "Accuracy: 0.865547792095315\n",
      "\n",
      "true positives\tfalse positives\tfalse negatives\ttrue negatives\n",
      "73815\t\t11480\t\t8\t\t140\n",
      "\n",
      "Class\t\t 0\t\t1\n",
      "Precision\t 1.00\t\t0.01\n",
      "recall\t\t 0.87\t\t0.95\n",
      "f1\t\t 0.93\t\t0.02\n",
      "support\t\t 85295.00\t148.00\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set \n",
    "predictions_us = log_reg_us_best.predict(X_test)\n",
    "print('Acc:', log_reg_us_best.score(X_test, y_test), '\\n')\n",
    "\n",
    "print_metrics(y_test, predictions_us, \"régression logistique avec sub-sample aléatoire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Références\n",
    "[Addressing the Curse of Imbalanced Training Sets: One-Sided Selection](https://sci2s.ugr.es/keel/pdf/algorithm/congreso/kubat97addressing.pdf)\n",
    "\n",
    "[Credit Fraud Detector (notebook kaggle)](https://www.kaggle.com/kernels/scriptcontent/16695845/download)\n",
    "\n",
    "[Toward data science article](https://towardsdatascience.com/detecting-financial-fraud-using-machine-learning-three-ways-of-winning-the-war-against-imbalanced-a03f8815cce9)\n",
    "\n",
    "[Evaluation Metrics, ROC-Curves and imbalanced datasets](http://www.davidsbatista.net/blog/2018/08/19/NLP_Metrics/)\n",
    "\n",
    "[Subsampling and Oversampling Wikipedia](https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis#Undersampling_techniques_for_classification_problems)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
